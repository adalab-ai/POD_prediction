{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitpharmenvvenv81b1c998f3a049c792cb4cfc384bcfa0",
   "display_name": "Python 3.6.9 64-bit ('pharm_env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, mutual_info_classif, f_classif, VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.abspath(\"/home/angelie/Documents/AdaLab/pharmaimage/data/yeo_Y/z/median/uni_clip_0.9999/multi_clip_N\") # use iterative imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.load(os.path.join(data_path, 'df.pkl'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_names = np.load(os.path.join(data_path, 'blood_names.npy'), allow_pickle=True)\n",
    "clinical_names = np.load(os.path.join(data_path, 'clinical_names.npy'), allow_pickle=True)\n",
    "imaging_names = np.load(os.path.join(data_path, 'imaging_names.npy'), allow_pickle=True)\n",
    "missing_feat_names = np.load(os.path.join(data_path, 'missing_feat_names.npy'), allow_pickle=True)\n",
    "static_names = np.load(os.path.join(data_path, 'static_names.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     blood_T1_Proinsulinintakt  blood_T1_oxLDL  blood_T1_Nitrotyrosin  \\\n0                    -0.003451       -0.004083               -0.03756   \n1                    -0.003451       -0.004083               -0.03756   \n2                    -0.003451       -0.004083               -0.03756   \n3                    -0.003451       -0.004083               -0.03756   \n4                    -0.003451       -0.004083               -0.03756   \n..                         ...             ...                    ...   \n928                  -0.003451       -0.004083               -0.03756   \n929                  -0.003451       -0.004083               -0.03756   \n930                  -0.003451       -0.004083               -0.03756   \n931                  -0.003451       -0.004083               -0.03756   \n932                  -0.003451       -0.004083               -0.03756   \n\n     blood_T1_S100A12_plasma  blood_T1_Calprotectinn  blood_T1_Zonulin_N1200  \\\n0                    0.02467                0.029969               -0.086108   \n1                    0.02467                0.029969               -0.086108   \n2                    0.02467                0.029969               -0.086108   \n3                    0.02467                0.029969               -0.086108   \n4                    0.02467                0.029969               -0.086108   \n..                       ...                     ...                     ...   \n928                  0.02467                0.029969               -0.777939   \n929                  0.02467                0.029969               -1.558332   \n930                  0.02467                0.029969               -0.395685   \n931                  0.02467                0.029969               -1.329304   \n932                  0.02467                0.029969               -0.808403   \n\n     blood_T1_hArginin  blood_T1_SDMA  blood_T1_KNYAcid  \\\n0              0.05213      -0.005613          0.010919   \n1              0.05213      -0.005613          0.010919   \n2              0.05213      -0.005613          0.010919   \n3              0.05213      -0.005613          0.010919   \n4              0.05213      -0.005613          0.010919   \n..                 ...            ...               ...   \n928            0.05213      -0.005613          0.010919   \n929            0.05213      -0.005613          0.010919   \n930            0.05213      -0.005613          0.010919   \n931            0.05213      -0.005613          0.010919   \n932            0.05213      -0.005613          0.010919   \n\n     blood_T1_NTproBNP_MissingRepl  ...  clinical_diabetes_any_nan  \\\n0                        -0.139004  ...                        0.0   \n1                        -0.139004  ...                        0.0   \n2                        -0.139004  ...                        0.0   \n3                        -0.139004  ...                        0.0   \n4                        -0.139004  ...                        0.0   \n..                             ...  ...                        ...   \n928                      -0.139004  ...                        0.0   \n929                      -0.139004  ...                        0.0   \n930                      -0.139004  ...                        0.0   \n931                      -0.139004  ...                        0.0   \n932                      -0.139004  ...                        0.0   \n\n     clinical_localisation_ThrAbdPlv_nan  clinical_MNA_mal_nan  \\\n0                                    0.0                   0.0   \n1                                    0.0                   0.0   \n2                                    0.0                   0.0   \n3                                    0.0                   0.0   \n4                                    0.0                   0.0   \n..                                   ...                   ...   \n928                                  0.0                   0.0   \n929                                  0.0                   0.0   \n930                                  0.0                   0.0   \n931                                  0.0                   0.0   \n932                                  0.0                   0.0   \n\n     clinical_MNA_normal_nan  clinical_MNA_risk_nan  \\\n0                        0.0                    0.0   \n1                        0.0                    0.0   \n2                        0.0                    0.0   \n3                        0.0                    0.0   \n4                        0.0                    0.0   \n..                       ...                    ...   \n928                      0.0                    0.0   \n929                      0.0                    0.0   \n930                      0.0                    0.0   \n931                      0.0                    0.0   \n932                      0.0                    0.0   \n\n     clinical_anaesth_type_combined_nan  clinical_anaesth_type_general_nan  \\\n0                                   0.0                                0.0   \n1                                   0.0                                0.0   \n2                                   0.0                                0.0   \n3                                   0.0                                0.0   \n4                                   0.0                                0.0   \n..                                  ...                                ...   \n928                                 0.0                                0.0   \n929                                 0.0                                0.0   \n930                                 0.0                                0.0   \n931                                 0.0                                0.0   \n932                                 0.0                                0.0   \n\n     clinical_anaesth_type_regional_nan  POD  POCD  \n0                                   0.0  0.0     1  \n1                                   0.0  0.0     0  \n2                                   0.0  1.0     0  \n3                                   0.0  0.0     0  \n4                                   0.0  0.0     0  \n..                                  ...  ...   ...  \n928                                 0.0  0.0    -1  \n929                                 0.0  0.0     1  \n930                                 0.0  0.0     0  \n931                                 0.0  0.0     0  \n932                                 0.0  0.0    -1  \n\n[929 rows x 1355 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>blood_T1_Proinsulinintakt</th>\n      <th>blood_T1_oxLDL</th>\n      <th>blood_T1_Nitrotyrosin</th>\n      <th>blood_T1_S100A12_plasma</th>\n      <th>blood_T1_Calprotectinn</th>\n      <th>blood_T1_Zonulin_N1200</th>\n      <th>blood_T1_hArginin</th>\n      <th>blood_T1_SDMA</th>\n      <th>blood_T1_KNYAcid</th>\n      <th>blood_T1_NTproBNP_MissingRepl</th>\n      <th>...</th>\n      <th>clinical_diabetes_any_nan</th>\n      <th>clinical_localisation_ThrAbdPlv_nan</th>\n      <th>clinical_MNA_mal_nan</th>\n      <th>clinical_MNA_normal_nan</th>\n      <th>clinical_MNA_risk_nan</th>\n      <th>clinical_anaesth_type_combined_nan</th>\n      <th>clinical_anaesth_type_general_nan</th>\n      <th>clinical_anaesth_type_regional_nan</th>\n      <th>POD</th>\n      <th>POCD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-0.086108</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-0.086108</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-0.086108</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-0.086108</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-0.086108</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-0.777939</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-1.558332</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-0.395685</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>931</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-1.329304</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>932</th>\n      <td>-0.003451</td>\n      <td>-0.004083</td>\n      <td>-0.03756</td>\n      <td>0.02467</td>\n      <td>0.029969</td>\n      <td>-0.808403</td>\n      <td>0.05213</td>\n      <td>-0.005613</td>\n      <td>0.010919</td>\n      <td>-0.139004</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>929 rows × 1355 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     brain_lh_Pole_occipital_thickness  brain_Rightchoroidplexus  \\\n0                            -1.299121                  1.137055   \n1                            -0.233560                  2.784536   \n2                            -1.307162                  0.803323   \n3                             0.793610                 -0.634606   \n4                            -0.052495                 -0.954663   \n..                                 ...                       ...   \n916                          -1.619912                 -0.186848   \n917                           1.333503                 -1.732256   \n922                          -0.744259                 -0.653758   \n923                          -0.483685                 -0.953248   \n926                           0.142420                  0.195465   \n\n     brain_lh_GS_cingulMidAnt_volume  brain_rh_Pole_occipital_area  \\\n0                          -0.002863                     -0.667461   \n1                          -1.538087                     -1.182695   \n2                          -0.544390                      0.927085   \n3                           1.892528                      0.772154   \n4                           2.152257                      0.473310   \n..                               ...                           ...   \n916                        -0.176087                      0.065950   \n917                         0.517992                      0.087518   \n922                        -0.573968                      0.271309   \n923                        -0.743764                     -0.113094   \n926                         0.895636                     -0.370535   \n\n     brain_lh_paracentral_area  brain_rh_G_octemp_latfusifor_volume  \\\n0                     0.203754                             0.412556   \n1                    -0.682614                             0.097645   \n2                    -2.855905                             0.414994   \n3                     0.155156                            -0.949866   \n4                     0.038793                            -0.125423   \n..                         ...                                  ...   \n916                  -0.401920                            -0.977277   \n917                  -0.280369                             0.445383   \n922                   0.057256                            -0.370599   \n923                  -0.735723                            -0.857888   \n926                   0.449224                             1.414719   \n\n     brain_rh_superiortemporal_meancurv  brain_middletemporal_area  \\\n0                             -0.797585                   0.794933   \n1                              1.074247                   0.499231   \n2                             -1.428322                  -0.567923   \n3                             -0.295459                   0.574625   \n4                             -0.295459                   1.402456   \n..                                  ...                        ...   \n916                           -0.797585                  -1.668195   \n917                            0.079710                  -1.035851   \n922                            0.578049                  -0.272394   \n923                           -0.295459                  -0.890402   \n926                            0.204496                   0.923815   \n\n     brain_rh_S_suborbital_meancurv  brain_lh_S_circular_insula_sup_area  ...  \\\n0                         -1.150401                             0.732899  ...   \n1                         -1.294970                             0.401506  ...   \n2                          1.466017                             0.861928  ...   \n3                         -2.492514                             0.416511  ...   \n4                          0.649892                             0.550385  ...   \n..                              ...                                  ...  ...   \n916                       -0.231185                             0.594546  ...   \n917                       -0.311274                            -0.534053  ...   \n922                       -2.048330                             0.119033  ...   \n923                       -1.294970                            -1.982021  ...   \n926                       -0.231185                            -0.245711  ...   \n\n     brain_rh_GS_cingulAnt_area  brain_lh_G_temp_supPlan_tempo_thickness  \\\n0                     -0.689900                                -0.051939   \n1                      1.466544                                -1.924424   \n2                     -1.302673                                -0.020196   \n3                      1.076249                                -1.672034   \n4                      0.422140                                 1.121209   \n..                          ...                                      ...   \n916                   -0.723327                                -0.178768   \n917                    0.018706                                -0.220993   \n922                   -0.839571                                -0.336980   \n923                   -0.946074                                -0.036069   \n926                   -0.923129                                 0.756595   \n\n     brain_rh_S_circular_insula_ant_meancurv  \\\n0                                   1.649432   \n1                                   0.710975   \n2                                  -0.609555   \n3                                   0.579262   \n4                                   0.305210   \n..                                       ...   \n916                                 0.710975   \n917                                 1.432809   \n922                                 0.162668   \n923                                 0.775547   \n926                                 0.645551   \n\n     brain_rh_GS_cingulMidPost_thickness  brain_rh_superiorparietal_meancurv  \\\n0                               0.506944                            1.979041   \n1                              -1.301807                            1.979041   \n2                              -2.449671                            0.129510   \n3                               0.275818                            2.694411   \n4                               0.696500                            1.347034   \n..                                   ...                                 ...   \n916                             0.441698                           -0.204001   \n917                            -0.576502                           -1.032098   \n922                            -0.030987                            0.019709   \n923                            -0.165176                           -0.204001   \n926                             2.137699                           -0.204001   \n\n     brain_lh_S_orbitalH_Shaped_meancurv  \\\n0                               0.481703   \n1                              -0.469454   \n2                              -1.601674   \n3                               0.290916   \n4                              -0.942429   \n..                                   ...   \n916                             0.768403   \n917                             0.672767   \n922                             0.959883   \n923                            -0.089824   \n926                             0.481703   \n\n     brain_lh_G_pariet_infAngular_thickness  brain_rh_paracentral_thickness  \\\n0                                 -1.041434                        0.184151   \n1                                 -0.565860                       -1.522595   \n2                                  0.015996                       -1.901817   \n3                                 -0.034535                       -1.326479   \n4                                 -0.097717                        1.510682   \n..                                      ...                             ...   \n916                               -0.028218                        0.730574   \n917                                0.564735                        1.379041   \n922                               -1.327323                       -0.667504   \n923                                0.841719                       -0.418336   \n926                                1.388347                        0.088899   \n\n     brain_rh_S_interm_primJensen_area  brain_Leftchoroidplexus  \n0                             0.160230                 0.196258  \n1                            -1.231988                 2.813286  \n2                            -0.824635                 0.834052  \n3                            -0.660740                -0.256443  \n4                             1.029244                -0.419435  \n..                                 ...                      ...  \n916                          -1.393856                -0.984982  \n917                          -0.112295                -2.226511  \n922                          -0.248936                -1.156242  \n923                           0.455197                -0.791684  \n926                           0.702887                -0.344095  \n\n[492 rows x 1083 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brain_lh_Pole_occipital_thickness</th>\n      <th>brain_Rightchoroidplexus</th>\n      <th>brain_lh_GS_cingulMidAnt_volume</th>\n      <th>brain_rh_Pole_occipital_area</th>\n      <th>brain_lh_paracentral_area</th>\n      <th>brain_rh_G_octemp_latfusifor_volume</th>\n      <th>brain_rh_superiortemporal_meancurv</th>\n      <th>brain_middletemporal_area</th>\n      <th>brain_rh_S_suborbital_meancurv</th>\n      <th>brain_lh_S_circular_insula_sup_area</th>\n      <th>...</th>\n      <th>brain_rh_GS_cingulAnt_area</th>\n      <th>brain_lh_G_temp_supPlan_tempo_thickness</th>\n      <th>brain_rh_S_circular_insula_ant_meancurv</th>\n      <th>brain_rh_GS_cingulMidPost_thickness</th>\n      <th>brain_rh_superiorparietal_meancurv</th>\n      <th>brain_lh_S_orbitalH_Shaped_meancurv</th>\n      <th>brain_lh_G_pariet_infAngular_thickness</th>\n      <th>brain_rh_paracentral_thickness</th>\n      <th>brain_rh_S_interm_primJensen_area</th>\n      <th>brain_Leftchoroidplexus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.299121</td>\n      <td>1.137055</td>\n      <td>-0.002863</td>\n      <td>-0.667461</td>\n      <td>0.203754</td>\n      <td>0.412556</td>\n      <td>-0.797585</td>\n      <td>0.794933</td>\n      <td>-1.150401</td>\n      <td>0.732899</td>\n      <td>...</td>\n      <td>-0.689900</td>\n      <td>-0.051939</td>\n      <td>1.649432</td>\n      <td>0.506944</td>\n      <td>1.979041</td>\n      <td>0.481703</td>\n      <td>-1.041434</td>\n      <td>0.184151</td>\n      <td>0.160230</td>\n      <td>0.196258</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.233560</td>\n      <td>2.784536</td>\n      <td>-1.538087</td>\n      <td>-1.182695</td>\n      <td>-0.682614</td>\n      <td>0.097645</td>\n      <td>1.074247</td>\n      <td>0.499231</td>\n      <td>-1.294970</td>\n      <td>0.401506</td>\n      <td>...</td>\n      <td>1.466544</td>\n      <td>-1.924424</td>\n      <td>0.710975</td>\n      <td>-1.301807</td>\n      <td>1.979041</td>\n      <td>-0.469454</td>\n      <td>-0.565860</td>\n      <td>-1.522595</td>\n      <td>-1.231988</td>\n      <td>2.813286</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.307162</td>\n      <td>0.803323</td>\n      <td>-0.544390</td>\n      <td>0.927085</td>\n      <td>-2.855905</td>\n      <td>0.414994</td>\n      <td>-1.428322</td>\n      <td>-0.567923</td>\n      <td>1.466017</td>\n      <td>0.861928</td>\n      <td>...</td>\n      <td>-1.302673</td>\n      <td>-0.020196</td>\n      <td>-0.609555</td>\n      <td>-2.449671</td>\n      <td>0.129510</td>\n      <td>-1.601674</td>\n      <td>0.015996</td>\n      <td>-1.901817</td>\n      <td>-0.824635</td>\n      <td>0.834052</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.793610</td>\n      <td>-0.634606</td>\n      <td>1.892528</td>\n      <td>0.772154</td>\n      <td>0.155156</td>\n      <td>-0.949866</td>\n      <td>-0.295459</td>\n      <td>0.574625</td>\n      <td>-2.492514</td>\n      <td>0.416511</td>\n      <td>...</td>\n      <td>1.076249</td>\n      <td>-1.672034</td>\n      <td>0.579262</td>\n      <td>0.275818</td>\n      <td>2.694411</td>\n      <td>0.290916</td>\n      <td>-0.034535</td>\n      <td>-1.326479</td>\n      <td>-0.660740</td>\n      <td>-0.256443</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.052495</td>\n      <td>-0.954663</td>\n      <td>2.152257</td>\n      <td>0.473310</td>\n      <td>0.038793</td>\n      <td>-0.125423</td>\n      <td>-0.295459</td>\n      <td>1.402456</td>\n      <td>0.649892</td>\n      <td>0.550385</td>\n      <td>...</td>\n      <td>0.422140</td>\n      <td>1.121209</td>\n      <td>0.305210</td>\n      <td>0.696500</td>\n      <td>1.347034</td>\n      <td>-0.942429</td>\n      <td>-0.097717</td>\n      <td>1.510682</td>\n      <td>1.029244</td>\n      <td>-0.419435</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>916</th>\n      <td>-1.619912</td>\n      <td>-0.186848</td>\n      <td>-0.176087</td>\n      <td>0.065950</td>\n      <td>-0.401920</td>\n      <td>-0.977277</td>\n      <td>-0.797585</td>\n      <td>-1.668195</td>\n      <td>-0.231185</td>\n      <td>0.594546</td>\n      <td>...</td>\n      <td>-0.723327</td>\n      <td>-0.178768</td>\n      <td>0.710975</td>\n      <td>0.441698</td>\n      <td>-0.204001</td>\n      <td>0.768403</td>\n      <td>-0.028218</td>\n      <td>0.730574</td>\n      <td>-1.393856</td>\n      <td>-0.984982</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>1.333503</td>\n      <td>-1.732256</td>\n      <td>0.517992</td>\n      <td>0.087518</td>\n      <td>-0.280369</td>\n      <td>0.445383</td>\n      <td>0.079710</td>\n      <td>-1.035851</td>\n      <td>-0.311274</td>\n      <td>-0.534053</td>\n      <td>...</td>\n      <td>0.018706</td>\n      <td>-0.220993</td>\n      <td>1.432809</td>\n      <td>-0.576502</td>\n      <td>-1.032098</td>\n      <td>0.672767</td>\n      <td>0.564735</td>\n      <td>1.379041</td>\n      <td>-0.112295</td>\n      <td>-2.226511</td>\n    </tr>\n    <tr>\n      <th>922</th>\n      <td>-0.744259</td>\n      <td>-0.653758</td>\n      <td>-0.573968</td>\n      <td>0.271309</td>\n      <td>0.057256</td>\n      <td>-0.370599</td>\n      <td>0.578049</td>\n      <td>-0.272394</td>\n      <td>-2.048330</td>\n      <td>0.119033</td>\n      <td>...</td>\n      <td>-0.839571</td>\n      <td>-0.336980</td>\n      <td>0.162668</td>\n      <td>-0.030987</td>\n      <td>0.019709</td>\n      <td>0.959883</td>\n      <td>-1.327323</td>\n      <td>-0.667504</td>\n      <td>-0.248936</td>\n      <td>-1.156242</td>\n    </tr>\n    <tr>\n      <th>923</th>\n      <td>-0.483685</td>\n      <td>-0.953248</td>\n      <td>-0.743764</td>\n      <td>-0.113094</td>\n      <td>-0.735723</td>\n      <td>-0.857888</td>\n      <td>-0.295459</td>\n      <td>-0.890402</td>\n      <td>-1.294970</td>\n      <td>-1.982021</td>\n      <td>...</td>\n      <td>-0.946074</td>\n      <td>-0.036069</td>\n      <td>0.775547</td>\n      <td>-0.165176</td>\n      <td>-0.204001</td>\n      <td>-0.089824</td>\n      <td>0.841719</td>\n      <td>-0.418336</td>\n      <td>0.455197</td>\n      <td>-0.791684</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>0.142420</td>\n      <td>0.195465</td>\n      <td>0.895636</td>\n      <td>-0.370535</td>\n      <td>0.449224</td>\n      <td>1.414719</td>\n      <td>0.204496</td>\n      <td>0.923815</td>\n      <td>-0.231185</td>\n      <td>-0.245711</td>\n      <td>...</td>\n      <td>-0.923129</td>\n      <td>0.756595</td>\n      <td>0.645551</td>\n      <td>2.137699</td>\n      <td>-0.204001</td>\n      <td>0.481703</td>\n      <td>1.388347</td>\n      <td>0.088899</td>\n      <td>0.702887</td>\n      <td>-0.344095</td>\n    </tr>\n  </tbody>\n</table>\n<p>492 rows × 1083 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df.loc[df['brain_imaging_regions_nan']==0, imaging_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     brain_lh_Pole_occipital_thickness  brain_Rightchoroidplexus  \\\n0                            -1.299121                  1.137055   \n1                            -0.233560                  2.784536   \n2                            -1.307162                  0.803323   \n3                             0.793610                 -0.634606   \n4                            -0.052495                 -0.954663   \n..                                 ...                       ...   \n910                          -0.781308                  0.205110   \n917                           1.333503                 -1.732256   \n922                          -0.744259                 -0.653758   \n923                          -0.483685                 -0.953248   \n926                           0.142420                  0.195465   \n\n     brain_lh_GS_cingulMidAnt_volume  brain_rh_Pole_occipital_area  \\\n0                          -0.002863                     -0.667461   \n1                          -1.538087                     -1.182695   \n2                          -0.544390                      0.927085   \n3                           1.892528                      0.772154   \n4                           2.152257                      0.473310   \n..                               ...                           ...   \n910                        -1.066978                      0.162411   \n917                         0.517992                      0.087518   \n922                        -0.573968                      0.271309   \n923                        -0.743764                     -0.113094   \n926                         0.895636                     -0.370535   \n\n     brain_lh_paracentral_area  brain_rh_G_octemp_latfusifor_volume  \\\n0                     0.203754                             0.412556   \n1                    -0.682614                             0.097645   \n2                    -2.855905                             0.414994   \n3                     0.155156                            -0.949866   \n4                     0.038793                            -0.125423   \n..                         ...                                  ...   \n910                  -0.401920                             0.933120   \n917                  -0.280369                             0.445383   \n922                   0.057256                            -0.370599   \n923                  -0.735723                            -0.857888   \n926                   0.449224                             1.414719   \n\n     brain_rh_superiortemporal_meancurv  brain_middletemporal_area  \\\n0                             -0.797585                   0.794933   \n1                              1.074247                   0.499231   \n2                             -1.428322                  -0.567923   \n3                             -0.295459                   0.574625   \n4                             -0.295459                   1.402456   \n..                                  ...                        ...   \n910                           -0.546250                  -0.312097   \n917                            0.079710                  -1.035851   \n922                            0.578049                  -0.272394   \n923                           -0.295459                  -0.890402   \n926                            0.204496                   0.923815   \n\n     brain_rh_S_suborbital_meancurv  brain_lh_S_circular_insula_sup_area  ...  \\\n0                         -1.150401                             0.732899  ...   \n1                         -1.294970                             0.401506  ...   \n2                          1.466017                             0.861928  ...   \n3                         -2.492514                             0.416511  ...   \n4                          0.649892                             0.550385  ...   \n..                              ...                                  ...  ...   \n910                        0.915510                            -0.517311  ...   \n917                       -0.311274                            -0.534053  ...   \n922                       -2.048330                             0.119033  ...   \n923                       -1.294970                            -1.982021  ...   \n926                       -0.231185                            -0.245711  ...   \n\n     brain_rh_GS_cingulAnt_area  brain_lh_G_temp_supPlan_tempo_thickness  \\\n0                     -0.689900                                -0.051939   \n1                      1.466544                                -1.924424   \n2                     -1.302673                                -0.020196   \n3                      1.076249                                -1.672034   \n4                      0.422140                                 1.121209   \n..                          ...                                      ...   \n910                   -0.667693                                 0.660376   \n917                    0.018706                                -0.220993   \n922                   -0.839571                                -0.336980   \n923                   -0.946074                                -0.036069   \n926                   -0.923129                                 0.756595   \n\n     brain_rh_S_circular_insula_ant_meancurv  \\\n0                                   1.649432   \n1                                   0.710975   \n2                                  -0.609555   \n3                                   0.579262   \n4                                   0.305210   \n..                                       ...   \n910                                -0.948402   \n917                                 1.432809   \n922                                 0.162668   \n923                                 0.775547   \n926                                 0.645551   \n\n     brain_rh_GS_cingulMidPost_thickness  brain_rh_superiorparietal_meancurv  \\\n0                               0.506944                            1.979041   \n1                              -1.301807                            1.979041   \n2                              -2.449671                            0.129510   \n3                               0.275818                            2.694411   \n4                               0.696500                            1.347034   \n..                                   ...                                 ...   \n910                            -0.707237                           -0.668377   \n917                            -0.576502                           -1.032098   \n922                            -0.030987                            0.019709   \n923                            -0.165176                           -0.204001   \n926                             2.137699                           -0.204001   \n\n     brain_lh_S_orbitalH_Shaped_meancurv  \\\n0                               0.481703   \n1                              -0.469454   \n2                              -1.601674   \n3                               0.290916   \n4                              -0.942429   \n..                                   ...   \n910                            -0.374651   \n917                             0.672767   \n922                             0.959883   \n923                            -0.089824   \n926                             0.481703   \n\n     brain_lh_G_pariet_infAngular_thickness  brain_rh_paracentral_thickness  \\\n0                                 -1.041434                        0.184151   \n1                                 -0.565860                       -1.522595   \n2                                  0.015996                       -1.901817   \n3                                 -0.034535                       -1.326479   \n4                                 -0.097717                        1.510682   \n..                                      ...                             ...   \n910                               -0.243106                        0.747553   \n917                                0.564735                        1.379041   \n922                               -1.327323                       -0.667504   \n923                                0.841719                       -0.418336   \n926                                1.388347                        0.088899   \n\n     brain_rh_S_interm_primJensen_area  brain_Leftchoroidplexus  \n0                             0.160230                 0.196258  \n1                            -1.231988                 2.813286  \n2                            -0.824635                 0.834052  \n3                            -0.660740                -0.256443  \n4                             1.029244                -0.419435  \n..                                 ...                      ...  \n910                           0.251209                 0.648481  \n917                          -0.112295                -2.226511  \n922                          -0.248936                -1.156242  \n923                           0.455197                -0.791684  \n926                           0.702887                -0.344095  \n\n[478 rows x 1083 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brain_lh_Pole_occipital_thickness</th>\n      <th>brain_Rightchoroidplexus</th>\n      <th>brain_lh_GS_cingulMidAnt_volume</th>\n      <th>brain_rh_Pole_occipital_area</th>\n      <th>brain_lh_paracentral_area</th>\n      <th>brain_rh_G_octemp_latfusifor_volume</th>\n      <th>brain_rh_superiortemporal_meancurv</th>\n      <th>brain_middletemporal_area</th>\n      <th>brain_rh_S_suborbital_meancurv</th>\n      <th>brain_lh_S_circular_insula_sup_area</th>\n      <th>...</th>\n      <th>brain_rh_GS_cingulAnt_area</th>\n      <th>brain_lh_G_temp_supPlan_tempo_thickness</th>\n      <th>brain_rh_S_circular_insula_ant_meancurv</th>\n      <th>brain_rh_GS_cingulMidPost_thickness</th>\n      <th>brain_rh_superiorparietal_meancurv</th>\n      <th>brain_lh_S_orbitalH_Shaped_meancurv</th>\n      <th>brain_lh_G_pariet_infAngular_thickness</th>\n      <th>brain_rh_paracentral_thickness</th>\n      <th>brain_rh_S_interm_primJensen_area</th>\n      <th>brain_Leftchoroidplexus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.299121</td>\n      <td>1.137055</td>\n      <td>-0.002863</td>\n      <td>-0.667461</td>\n      <td>0.203754</td>\n      <td>0.412556</td>\n      <td>-0.797585</td>\n      <td>0.794933</td>\n      <td>-1.150401</td>\n      <td>0.732899</td>\n      <td>...</td>\n      <td>-0.689900</td>\n      <td>-0.051939</td>\n      <td>1.649432</td>\n      <td>0.506944</td>\n      <td>1.979041</td>\n      <td>0.481703</td>\n      <td>-1.041434</td>\n      <td>0.184151</td>\n      <td>0.160230</td>\n      <td>0.196258</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.233560</td>\n      <td>2.784536</td>\n      <td>-1.538087</td>\n      <td>-1.182695</td>\n      <td>-0.682614</td>\n      <td>0.097645</td>\n      <td>1.074247</td>\n      <td>0.499231</td>\n      <td>-1.294970</td>\n      <td>0.401506</td>\n      <td>...</td>\n      <td>1.466544</td>\n      <td>-1.924424</td>\n      <td>0.710975</td>\n      <td>-1.301807</td>\n      <td>1.979041</td>\n      <td>-0.469454</td>\n      <td>-0.565860</td>\n      <td>-1.522595</td>\n      <td>-1.231988</td>\n      <td>2.813286</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.307162</td>\n      <td>0.803323</td>\n      <td>-0.544390</td>\n      <td>0.927085</td>\n      <td>-2.855905</td>\n      <td>0.414994</td>\n      <td>-1.428322</td>\n      <td>-0.567923</td>\n      <td>1.466017</td>\n      <td>0.861928</td>\n      <td>...</td>\n      <td>-1.302673</td>\n      <td>-0.020196</td>\n      <td>-0.609555</td>\n      <td>-2.449671</td>\n      <td>0.129510</td>\n      <td>-1.601674</td>\n      <td>0.015996</td>\n      <td>-1.901817</td>\n      <td>-0.824635</td>\n      <td>0.834052</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.793610</td>\n      <td>-0.634606</td>\n      <td>1.892528</td>\n      <td>0.772154</td>\n      <td>0.155156</td>\n      <td>-0.949866</td>\n      <td>-0.295459</td>\n      <td>0.574625</td>\n      <td>-2.492514</td>\n      <td>0.416511</td>\n      <td>...</td>\n      <td>1.076249</td>\n      <td>-1.672034</td>\n      <td>0.579262</td>\n      <td>0.275818</td>\n      <td>2.694411</td>\n      <td>0.290916</td>\n      <td>-0.034535</td>\n      <td>-1.326479</td>\n      <td>-0.660740</td>\n      <td>-0.256443</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.052495</td>\n      <td>-0.954663</td>\n      <td>2.152257</td>\n      <td>0.473310</td>\n      <td>0.038793</td>\n      <td>-0.125423</td>\n      <td>-0.295459</td>\n      <td>1.402456</td>\n      <td>0.649892</td>\n      <td>0.550385</td>\n      <td>...</td>\n      <td>0.422140</td>\n      <td>1.121209</td>\n      <td>0.305210</td>\n      <td>0.696500</td>\n      <td>1.347034</td>\n      <td>-0.942429</td>\n      <td>-0.097717</td>\n      <td>1.510682</td>\n      <td>1.029244</td>\n      <td>-0.419435</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>910</th>\n      <td>-0.781308</td>\n      <td>0.205110</td>\n      <td>-1.066978</td>\n      <td>0.162411</td>\n      <td>-0.401920</td>\n      <td>0.933120</td>\n      <td>-0.546250</td>\n      <td>-0.312097</td>\n      <td>0.915510</td>\n      <td>-0.517311</td>\n      <td>...</td>\n      <td>-0.667693</td>\n      <td>0.660376</td>\n      <td>-0.948402</td>\n      <td>-0.707237</td>\n      <td>-0.668377</td>\n      <td>-0.374651</td>\n      <td>-0.243106</td>\n      <td>0.747553</td>\n      <td>0.251209</td>\n      <td>0.648481</td>\n    </tr>\n    <tr>\n      <th>917</th>\n      <td>1.333503</td>\n      <td>-1.732256</td>\n      <td>0.517992</td>\n      <td>0.087518</td>\n      <td>-0.280369</td>\n      <td>0.445383</td>\n      <td>0.079710</td>\n      <td>-1.035851</td>\n      <td>-0.311274</td>\n      <td>-0.534053</td>\n      <td>...</td>\n      <td>0.018706</td>\n      <td>-0.220993</td>\n      <td>1.432809</td>\n      <td>-0.576502</td>\n      <td>-1.032098</td>\n      <td>0.672767</td>\n      <td>0.564735</td>\n      <td>1.379041</td>\n      <td>-0.112295</td>\n      <td>-2.226511</td>\n    </tr>\n    <tr>\n      <th>922</th>\n      <td>-0.744259</td>\n      <td>-0.653758</td>\n      <td>-0.573968</td>\n      <td>0.271309</td>\n      <td>0.057256</td>\n      <td>-0.370599</td>\n      <td>0.578049</td>\n      <td>-0.272394</td>\n      <td>-2.048330</td>\n      <td>0.119033</td>\n      <td>...</td>\n      <td>-0.839571</td>\n      <td>-0.336980</td>\n      <td>0.162668</td>\n      <td>-0.030987</td>\n      <td>0.019709</td>\n      <td>0.959883</td>\n      <td>-1.327323</td>\n      <td>-0.667504</td>\n      <td>-0.248936</td>\n      <td>-1.156242</td>\n    </tr>\n    <tr>\n      <th>923</th>\n      <td>-0.483685</td>\n      <td>-0.953248</td>\n      <td>-0.743764</td>\n      <td>-0.113094</td>\n      <td>-0.735723</td>\n      <td>-0.857888</td>\n      <td>-0.295459</td>\n      <td>-0.890402</td>\n      <td>-1.294970</td>\n      <td>-1.982021</td>\n      <td>...</td>\n      <td>-0.946074</td>\n      <td>-0.036069</td>\n      <td>0.775547</td>\n      <td>-0.165176</td>\n      <td>-0.204001</td>\n      <td>-0.089824</td>\n      <td>0.841719</td>\n      <td>-0.418336</td>\n      <td>0.455197</td>\n      <td>-0.791684</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>0.142420</td>\n      <td>0.195465</td>\n      <td>0.895636</td>\n      <td>-0.370535</td>\n      <td>0.449224</td>\n      <td>1.414719</td>\n      <td>0.204496</td>\n      <td>0.923815</td>\n      <td>-0.231185</td>\n      <td>-0.245711</td>\n      <td>...</td>\n      <td>-0.923129</td>\n      <td>0.756595</td>\n      <td>0.645551</td>\n      <td>2.137699</td>\n      <td>-0.204001</td>\n      <td>0.481703</td>\n      <td>1.388347</td>\n      <td>0.088899</td>\n      <td>0.702887</td>\n      <td>-0.344095</td>\n    </tr>\n  </tbody>\n</table>\n<p>478 rows × 1083 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df.loc[df['brain_imaging_cubic_vol_nan']==0, imaging_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     brain_imaging_regions_nan  brain_imaging_cubic_vol_nan\n0                          0.0                          0.0\n1                          0.0                          0.0\n2                          0.0                          0.0\n3                          0.0                          0.0\n4                          0.0                          0.0\n..                         ...                          ...\n928                        1.0                          1.0\n929                        1.0                          1.0\n930                        1.0                          1.0\n931                        1.0                          1.0\n932                        1.0                          1.0\n\n[929 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brain_imaging_regions_nan</th>\n      <th>brain_imaging_cubic_vol_nan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>931</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>932</th>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>929 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "imaging_missings = [col for col in missing_feat_names if col.startswith('brain_')]\n",
    "df[imaging_missings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     brain_lh_Pole_occipital_thickness  brain_Rightchoroidplexus  \\\n0                            -1.299121                  1.137055   \n1                            -0.233560                  2.784536   \n2                            -1.307162                  0.803323   \n3                             0.793610                 -0.634606   \n4                            -0.052495                 -0.954663   \n..                                 ...                       ...   \n928                          -0.022844                  0.032730   \n929                          -0.022844                  0.032730   \n930                          -0.022844                  0.032730   \n931                          -0.022844                  0.032730   \n932                          -0.022844                  0.032730   \n\n     brain_lh_GS_cingulMidAnt_volume  brain_rh_Pole_occipital_area  \\\n0                          -0.002863                     -0.667461   \n1                          -1.538087                     -1.182695   \n2                          -0.544390                      0.927085   \n3                           1.892528                      0.772154   \n4                           2.152257                      0.473310   \n..                               ...                           ...   \n928                        -0.002863                      0.009878   \n929                        -0.002863                      0.009878   \n930                        -0.002863                      0.009878   \n931                        -0.002863                      0.009878   \n932                        -0.002863                      0.009878   \n\n     brain_lh_paracentral_area  brain_rh_G_octemp_latfusifor_volume  \\\n0                     0.203754                             0.412556   \n1                    -0.682614                             0.097645   \n2                    -2.855905                             0.414994   \n3                     0.155156                            -0.949866   \n4                     0.038793                            -0.125423   \n..                         ...                                  ...   \n928                  -0.066472                             0.035828   \n929                  -0.066472                             0.035828   \n930                  -0.066472                             0.035828   \n931                  -0.066472                             0.035828   \n932                  -0.066472                             0.035828   \n\n     brain_rh_superiortemporal_meancurv  brain_middletemporal_area  \\\n0                             -0.797585                   0.794933   \n1                              1.074247                   0.499231   \n2                             -1.428322                  -0.567923   \n3                             -0.295459                   0.574625   \n4                             -0.295459                   1.402456   \n..                                  ...                        ...   \n928                           -0.045211                  -0.058922   \n929                           -0.045211                  -0.058922   \n930                           -0.045211                  -0.058922   \n931                           -0.045211                  -0.058922   \n932                           -0.045211                  -0.058922   \n\n     brain_rh_S_suborbital_meancurv  brain_lh_S_circular_insula_sup_area  ...  \\\n0                         -1.150401                             0.732899  ...   \n1                         -1.294970                             0.401506  ...   \n2                          1.466017                             0.861928  ...   \n3                         -2.492514                             0.416511  ...   \n4                          0.649892                             0.550385  ...   \n..                              ...                                  ...  ...   \n928                        0.013007                            -0.021843  ...   \n929                        0.013007                            -0.021843  ...   \n930                        0.013007                            -0.021843  ...   \n931                        0.013007                            -0.021843  ...   \n932                        0.013007                            -0.021843  ...   \n\n     blood_T1_Leptin_Adipon_Ratio  blood_T1_SORL1  blood_T1_IL2_pgml  \\\n0                       -0.072813        0.060185          -0.105497   \n1                       -0.072813        0.060185          -0.105497   \n2                       -0.072813        0.060185          -0.105497   \n3                       -0.072813        0.060185          -0.105497   \n4                       -0.072813        0.060185          -0.105497   \n..                            ...             ...                ...   \n928                      1.326354        0.329503          -0.105497   \n929                     -0.696991       -0.213660           0.382805   \n930                     -1.251085        1.992027           0.109548   \n931                     -1.775257        1.465710          -0.105497   \n932                     -1.189625        1.671139          -0.105497   \n\n     blood_T1_IL8_pgml  blood_T1_IL10_pgml  blood_T1_IL18_pgml  \\\n0            -0.131936           -0.233885            0.012586   \n1            -0.131936           -0.233885            0.012586   \n2            -0.131936           -0.233885            0.012586   \n3            -0.131936           -0.233885            0.012586   \n4            -0.131936           -0.233885            0.012586   \n..                 ...                 ...                 ...   \n928          -0.526285           -0.233885            0.162305   \n929          -0.131936           -0.233885            0.399490   \n930          -0.131936           -0.233885           -0.954567   \n931          -0.131936           -0.233885           -1.258537   \n932          -0.131936           -0.233885            0.279346   \n\n     blood_T1_Volk_IL8_pgml  blood_T1_IL18_pgml_Boraschi  \\\n0                 -0.287939                    -0.174007   \n1                 -0.287939                    -0.174007   \n2                 -0.287939                    -0.174007   \n3                 -0.287939                    -0.174007   \n4                 -0.287939                    -0.174007   \n..                      ...                          ...   \n928               -0.287939                    -0.174007   \n929               -0.287939                    -0.174007   \n930               -0.287939                    -0.174007   \n931               -0.287939                    -0.174007   \n932               -0.287939                    -0.174007   \n\n     blood_Final_T1_TP42_40  POD  \n0                 -0.018390  0.0  \n1                 -0.018390  0.0  \n2                 -0.018390  1.0  \n3                 -0.018390  0.0  \n4                 -0.018390  0.0  \n..                      ...  ...  \n928               -1.734236  0.0  \n929               -1.832048  0.0  \n930                0.446011  0.0  \n931               -0.481065  0.0  \n932                0.943048  0.0  \n\n[929 rows x 1220 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brain_lh_Pole_occipital_thickness</th>\n      <th>brain_Rightchoroidplexus</th>\n      <th>brain_lh_GS_cingulMidAnt_volume</th>\n      <th>brain_rh_Pole_occipital_area</th>\n      <th>brain_lh_paracentral_area</th>\n      <th>brain_rh_G_octemp_latfusifor_volume</th>\n      <th>brain_rh_superiortemporal_meancurv</th>\n      <th>brain_middletemporal_area</th>\n      <th>brain_rh_S_suborbital_meancurv</th>\n      <th>brain_lh_S_circular_insula_sup_area</th>\n      <th>...</th>\n      <th>blood_T1_Leptin_Adipon_Ratio</th>\n      <th>blood_T1_SORL1</th>\n      <th>blood_T1_IL2_pgml</th>\n      <th>blood_T1_IL8_pgml</th>\n      <th>blood_T1_IL10_pgml</th>\n      <th>blood_T1_IL18_pgml</th>\n      <th>blood_T1_Volk_IL8_pgml</th>\n      <th>blood_T1_IL18_pgml_Boraschi</th>\n      <th>blood_Final_T1_TP42_40</th>\n      <th>POD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.299121</td>\n      <td>1.137055</td>\n      <td>-0.002863</td>\n      <td>-0.667461</td>\n      <td>0.203754</td>\n      <td>0.412556</td>\n      <td>-0.797585</td>\n      <td>0.794933</td>\n      <td>-1.150401</td>\n      <td>0.732899</td>\n      <td>...</td>\n      <td>-0.072813</td>\n      <td>0.060185</td>\n      <td>-0.105497</td>\n      <td>-0.131936</td>\n      <td>-0.233885</td>\n      <td>0.012586</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>-0.018390</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.233560</td>\n      <td>2.784536</td>\n      <td>-1.538087</td>\n      <td>-1.182695</td>\n      <td>-0.682614</td>\n      <td>0.097645</td>\n      <td>1.074247</td>\n      <td>0.499231</td>\n      <td>-1.294970</td>\n      <td>0.401506</td>\n      <td>...</td>\n      <td>-0.072813</td>\n      <td>0.060185</td>\n      <td>-0.105497</td>\n      <td>-0.131936</td>\n      <td>-0.233885</td>\n      <td>0.012586</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>-0.018390</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.307162</td>\n      <td>0.803323</td>\n      <td>-0.544390</td>\n      <td>0.927085</td>\n      <td>-2.855905</td>\n      <td>0.414994</td>\n      <td>-1.428322</td>\n      <td>-0.567923</td>\n      <td>1.466017</td>\n      <td>0.861928</td>\n      <td>...</td>\n      <td>-0.072813</td>\n      <td>0.060185</td>\n      <td>-0.105497</td>\n      <td>-0.131936</td>\n      <td>-0.233885</td>\n      <td>0.012586</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>-0.018390</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.793610</td>\n      <td>-0.634606</td>\n      <td>1.892528</td>\n      <td>0.772154</td>\n      <td>0.155156</td>\n      <td>-0.949866</td>\n      <td>-0.295459</td>\n      <td>0.574625</td>\n      <td>-2.492514</td>\n      <td>0.416511</td>\n      <td>...</td>\n      <td>-0.072813</td>\n      <td>0.060185</td>\n      <td>-0.105497</td>\n      <td>-0.131936</td>\n      <td>-0.233885</td>\n      <td>0.012586</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>-0.018390</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.052495</td>\n      <td>-0.954663</td>\n      <td>2.152257</td>\n      <td>0.473310</td>\n      <td>0.038793</td>\n      <td>-0.125423</td>\n      <td>-0.295459</td>\n      <td>1.402456</td>\n      <td>0.649892</td>\n      <td>0.550385</td>\n      <td>...</td>\n      <td>-0.072813</td>\n      <td>0.060185</td>\n      <td>-0.105497</td>\n      <td>-0.131936</td>\n      <td>-0.233885</td>\n      <td>0.012586</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>-0.018390</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>-0.022844</td>\n      <td>0.032730</td>\n      <td>-0.002863</td>\n      <td>0.009878</td>\n      <td>-0.066472</td>\n      <td>0.035828</td>\n      <td>-0.045211</td>\n      <td>-0.058922</td>\n      <td>0.013007</td>\n      <td>-0.021843</td>\n      <td>...</td>\n      <td>1.326354</td>\n      <td>0.329503</td>\n      <td>-0.105497</td>\n      <td>-0.526285</td>\n      <td>-0.233885</td>\n      <td>0.162305</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>-1.734236</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>-0.022844</td>\n      <td>0.032730</td>\n      <td>-0.002863</td>\n      <td>0.009878</td>\n      <td>-0.066472</td>\n      <td>0.035828</td>\n      <td>-0.045211</td>\n      <td>-0.058922</td>\n      <td>0.013007</td>\n      <td>-0.021843</td>\n      <td>...</td>\n      <td>-0.696991</td>\n      <td>-0.213660</td>\n      <td>0.382805</td>\n      <td>-0.131936</td>\n      <td>-0.233885</td>\n      <td>0.399490</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>-1.832048</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>-0.022844</td>\n      <td>0.032730</td>\n      <td>-0.002863</td>\n      <td>0.009878</td>\n      <td>-0.066472</td>\n      <td>0.035828</td>\n      <td>-0.045211</td>\n      <td>-0.058922</td>\n      <td>0.013007</td>\n      <td>-0.021843</td>\n      <td>...</td>\n      <td>-1.251085</td>\n      <td>1.992027</td>\n      <td>0.109548</td>\n      <td>-0.131936</td>\n      <td>-0.233885</td>\n      <td>-0.954567</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>0.446011</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>931</th>\n      <td>-0.022844</td>\n      <td>0.032730</td>\n      <td>-0.002863</td>\n      <td>0.009878</td>\n      <td>-0.066472</td>\n      <td>0.035828</td>\n      <td>-0.045211</td>\n      <td>-0.058922</td>\n      <td>0.013007</td>\n      <td>-0.021843</td>\n      <td>...</td>\n      <td>-1.775257</td>\n      <td>1.465710</td>\n      <td>-0.105497</td>\n      <td>-0.131936</td>\n      <td>-0.233885</td>\n      <td>-1.258537</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>-0.481065</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>932</th>\n      <td>-0.022844</td>\n      <td>0.032730</td>\n      <td>-0.002863</td>\n      <td>0.009878</td>\n      <td>-0.066472</td>\n      <td>0.035828</td>\n      <td>-0.045211</td>\n      <td>-0.058922</td>\n      <td>0.013007</td>\n      <td>-0.021843</td>\n      <td>...</td>\n      <td>-1.189625</td>\n      <td>1.671139</td>\n      <td>-0.105497</td>\n      <td>-0.131936</td>\n      <td>-0.233885</td>\n      <td>0.279346</td>\n      <td>-0.287939</td>\n      <td>-0.174007</td>\n      <td>0.943048</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>929 rows × 1220 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "#all_df = pd.concat([df[imaging_names], df[clinical_names], df[blood_names], df[missing_feat_names], df[static_names], df['POD']], axis=1)\n",
    "all_df = pd.concat([df[imaging_names], df[clinical_names], df[static_names], df[blood_names], df['POD']], axis=1)\n",
    "#imaging_df = pd.concat([df[imaging_names], df[clinical_names], df['POD']], axis=1)\n",
    "#imaging_df = imaging_df.loc[df['brain_imaging_regions_nan']==1, :]\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "metadata": {},
     "execution_count": 10
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 375.2875 248.518125\" width=\"375.2875pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-09-10T13:38:49.475606</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 375.2875 248.518125 \nL 375.2875 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \nL 368.0875 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 48.505682 224.64 \nL 78.942045 224.64 \nL 78.942045 17.554286 \nL 48.505682 17.554286 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 78.942045 224.64 \nL 109.378409 224.64 \nL 109.378409 224.64 \nL 78.942045 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 109.378409 224.64 \nL 139.814773 224.64 \nL 139.814773 224.64 \nL 109.378409 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 139.814773 224.64 \nL 170.251136 224.64 \nL 170.251136 224.64 \nL 139.814773 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 170.251136 224.64 \nL 200.6875 224.64 \nL 200.6875 224.64 \nL 170.251136 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 200.6875 224.64 \nL 231.123864 224.64 \nL 231.123864 224.64 \nL 200.6875 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 231.123864 224.64 \nL 261.560227 224.64 \nL 261.560227 224.64 \nL 231.123864 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 261.560227 224.64 \nL 291.996591 224.64 \nL 291.996591 224.64 \nL 261.560227 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 291.996591 224.64 \nL 322.432955 224.64 \nL 322.432955 224.64 \nL 291.996591 224.64 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p101297ef31)\" d=\"M 322.432955 224.64 \nL 352.869318 224.64 \nL 352.869318 173.493998 \nL 322.432955 173.493998 \nz\n\" style=\"fill:#1f77b4;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 48.505682 224.64 \nL 48.505682 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m72dee8ef6c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.505682\" xlink:href=\"#m72dee8ef6c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <g transform=\"translate(40.554119 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 109.378409 224.64 \nL 109.378409 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"109.378409\" xlink:href=\"#m72dee8ef6c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 0.2 -->\n      <g transform=\"translate(101.426847 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 170.251136 224.64 \nL 170.251136 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.251136\" xlink:href=\"#m72dee8ef6c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 0.4 -->\n      <g transform=\"translate(162.299574 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 231.123864 224.64 \nL 231.123864 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.123864\" xlink:href=\"#m72dee8ef6c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 0.6 -->\n      <g transform=\"translate(223.172301 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 291.996591 224.64 \nL 291.996591 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"291.996591\" xlink:href=\"#m72dee8ef6c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.8 -->\n      <g transform=\"translate(284.045028 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 352.869318 224.64 \nL 352.869318 7.2 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.869318\" xlink:href=\"#m72dee8ef6c\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1.0 -->\n      <g transform=\"translate(344.917756 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 33.2875 224.64 \nL 368.0875 224.64 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m1ddd740e31\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1ddd740e31\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 228.439219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 33.2875 196.84326 \nL 368.0875 196.84326 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1ddd740e31\" y=\"196.84326\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 200.642479)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 33.2875 169.04652 \nL 368.0875 169.04652 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1ddd740e31\" y=\"169.04652\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(7.2 172.845738)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 33.2875 141.249779 \nL 368.0875 141.249779 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1ddd740e31\" y=\"141.249779\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 300 -->\n      <g transform=\"translate(7.2 145.048998)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 33.2875 113.453039 \nL 368.0875 113.453039 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1ddd740e31\" y=\"113.453039\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 400 -->\n      <g transform=\"translate(7.2 117.252258)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 33.2875 85.656299 \nL 368.0875 85.656299 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1ddd740e31\" y=\"85.656299\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 500 -->\n      <g transform=\"translate(7.2 89.455518)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 33.2875 57.859559 \nL 368.0875 57.859559 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1ddd740e31\" y=\"57.859559\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 600 -->\n      <g transform=\"translate(7.2 61.658778)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#p101297ef31)\" d=\"M 33.2875 30.062819 \nL 368.0875 30.062819 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.2875\" xlink:href=\"#m1ddd740e31\" y=\"30.062819\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 700 -->\n      <g transform=\"translate(7.2 33.862038)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 33.2875 224.64 \nL 33.2875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 368.0875 224.64 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 33.2875 224.64 \nL 368.0875 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 33.2875 7.2 \nL 368.0875 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p101297ef31\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.2875\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "all_df['POD'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.19806243272335844"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "all_df['POD'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate stuff\n",
    "https://scikit-learn.org/stable/modules/feature_selection.html#univariate-feature-selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_xgb(X_train, Y_train):\n",
    "    model = xgb.XGBClassifier(n_estimators=1000,\n",
    "                                  max_depth=10,\n",
    "                                  learning_rate=0.1)\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rf(X_train, Y_train):\n",
    "    model = RandomForestClassifier(n_estimators=10000)\n",
    "    model.fit(X_train, Y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_train(X_dev, Y_dev, indcs):\n",
    "    acc_scores, auc_scores = [], []\n",
    "    models = []\n",
    "    \n",
    "    for train_index, val_index in indcs:\n",
    "        model = fit_xgb(X_dev.iloc[train_index], Y_dev.iloc[train_index])\n",
    "        Y_pred = model.predict(X_dev.iloc[val_index])\n",
    "        acc_scores.append(accuracy_score(Y_pred, Y_dev.iloc[val_index]))\n",
    "        auc_scores.append(roc_auc_score(Y_pred, Y_dev.iloc[val_index]))\n",
    "        models.append(model)\n",
    "    print(f\"Mean accuracy over {len(indcs)} folds is {np.mean(acc_scores)}\")\n",
    "    print(f\"Mean AUC over {len(indcs)} folds is {np.mean(auc_scores)}\")\n",
    "\n",
    "    best_model_idx = np.where(auc_scores == np.amax(auc_scores))[0][0]\n",
    "    return models[best_model_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data\n",
    "X = all_df.loc[:, all_df.columns != 'POD']\n",
    "Y = all_df.loc[:, 'POD']\n",
    "X_dev, X_test, Y_dev, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=42)\n",
    "folds_indcs = [(train_index, val_index) for (train_index, val_index) in skf.split(X_dev, Y_dev)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean accuracy over 5 folds is 0.8349372683205019\nMean AUC over 5 folds is 0.7528667812035361\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=10,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=1000, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Before reduction\n",
    "run_train(X_dev, Y_dev, folds_indcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=1000,\n",
    "                                  max_depth=10,\n",
    "                                  learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting estimator with 1219 features.\nFitting estimator with 1098 features.\nFitting estimator with 977 features.\nFitting estimator with 856 features.\nFitting estimator with 735 features.\nFitting estimator with 614 features.\nFitting estimator with 493 features.\nOptimal number of features : 372\n"
    }
   ],
   "source": [
    "rfecv = RFECV(estimator=model, step=0.1, cv=StratifiedKFold(3, random_state=42),\n",
    "              scoring='roc_auc', verbose=1, n_jobs=-1) \n",
    "rfecv.fit(X_dev, Y_dev)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['brain_Rightchoroidplexus', 'brain_lh_GS_cingulMidAnt_volume', 'brain_rh_superiortemporal_meancurv', 'brain_middletemporal_area', 'brain_rh_S_oc_suptransversal_thickness', 'brain_lh_G_front_infOrbital_volume', 'brain_lh_S_suborbital_area', 'brain_lh_S_circular_insula_ant_meancurv', 'brain_rh_S_front_middle_area', 'brain_rh_S_subparietal_volume', 'brain_lh_GS_frontomargin_thickness', 'brain_rh_G_temporal_middle_volume', 'brain_lh_posteriorcingulate_thickness', 'brain_superiorfrontal_meancurv', 'brain_pericalcarine_meancurv', 'brain_lh_Lat_FisantVertical_area', 'brain_rh_S_circular_insula_sup_area', 'brain_lh_S_suborbital_volume', 'brain_rh_S_central_meancurv', 'brain_lh_fusiform_thickness', 'brain_lh_S_front_middle_meancurv', 'brain_rh_G_precuneus_meancurv', 'brain_rh_rostralanteriorcingulate_thickness', 'brain_lh_S_intraparietP_trans_area', 'brain_lh_lateraloccipital_thickness', 'brain_lh_middletemporal_thickness', 'brain_rh_GS_subcentral_meancurv', 'brain_rh_G_front_sup_meancurv', 'brain_lh_rostralanteriorcingulate_thickness', 'brain_rh_pericalcarine_thickness', 'brain_lh_bankssts_meancurv', 'brain_lh_G_subcallosal_volume', 'brain_lh_S_octemp_lat_meancurv', 'brain_rh_G_front_middle_meancurv', 'brain_rh_S_circular_insula_sup_volume', 'brain_lh_G_subcallosal_area', 'brain_lh_G_postcentral_meancurv', 'brain_lh_transversetemporal_meancurv', 'brain_lh_GS_cingulMidPost_meancurv', 'brain_rh_G_parietal_sup_area', 'brain_RightCerebellumWhiteMatter', 'brain_rh_S_parieto_occipital_meancurv', 'brain_CC_Posterior', 'brain_lh_G_temporal_middle_meancurv', 'brain_lh_medialorbitofrontal_meancurv', 'brain_lh_GS_paracentral_thickness', 'brain_lh_S_orbital_medolfact_volume', 'brain_rh_G_octemp_latfusifor_area', 'brain_cuneus_volume', 'brain_lh_paracentral_volume', 'brain_CSF', 'brain_rh_G_cuneus_thickness', 'brain_rh_S_parieto_occipital_area', 'brain_cuneus_thickness', 'brain_lh_bankssts_area', 'brain_lh_S_octemp_lat_area', 'brain_lh_GS_frontomargin_meancurv', 'brain_rh_GS_paracentral_volume', 'brain_lh_S_temporal_inf_thickness', 'brain_posteriorcingulate_thickness', 'brain_rh_S_circular_insula_inf_thickness', 'brain_pericalcarine_thickness', 'brain_lh_Lat_FisantVertical_thickness', 'brain_rh_G_temp_supPlan_tempo_area', 'brain_rh_S_collat_transv_ant_meancurv', 'brain_lh_G_cingulPostventral_meancurv', 'brain_rh_G_insular_short_area', 'brain_lh_S_calcarine_volume', 'brain_rh_G_temporal_inf_volume', 'brain_lh_Lat_FisantVertical_meancurv', 'brain_WMhypointensities', 'brain_lh_G_precuneus_meancurv', 'brain_lh_S_front_inf_meancurv', 'brain_lh_G_front_infTriangul_volume', 'brain_rh_S_orbital_medolfact_thickness', 'brain_lh_G_cingulPostventral_thickness', 'brain_lh_superiortemporal_thickness', 'brain_rh_lateralorbitofrontal_thickness', 'brain_rh_S_collat_transv_post_area', 'brain_rh_S_calcarine_area', 'brain_rh_parsorbitalis_thickness', 'brain_lh_rostralanteriorcingulate_meancurv', 'brain_medialorbitofrontal_thickness', 'brain_lh_S_collat_transv_post_volume', 'brain_lh_G_temporal_inf_volume', 'brain_lh_G_octemp_medParahip_thickness', 'brain_lh_S_suborbital_thickness', 'brain_lh_S_postcentral_area', 'brain_lh_G_precentral_area', 'brain_CC_Anterior', 'brain_lh_G_pariet_infAngular_meancurv', 'brain_rh_S_cingulMarginalis_meancurv', 'brain_lh_G_front_infOrbital_area', 'brain_rh_G_front_infTriangul_meancurv', 'brain_lh_S_pericallosal_meancurv', 'brain_lh_GS_cingulMidPost_thickness', 'brain_lh_G_front_infOrbital_thickness', 'brain_temporalpole_area', 'brain_rh_G_temp_supPlan_polar_thickness', 'brain_rh_S_central_volume', 'brain_temporalpole_volume', 'brain_rh_GS_occipital_inf_thickness', 'brain_rh_S_front_middle_meancurv', 'brain_lh_G_temp_supG_T_transv_thickness', 'brain_lh_medialorbitofrontal_area', 'brain_lh_pericalcarine_thickness', 'brain_lh_G_octemp_medParahip_area', 'brain_rh_middletemporal_area', 'brain_lh_temporalpole_volume', 'brain_lh_S_cingulMarginalis_volume', 'brain_rh_G_precentral_volume', 'brain_rh_pericalcarine_area', 'brain_rh_insula_thickness', 'brain_rh_lateralorbitofrontal_volume', 'brain_rh_S_circular_insula_sup_thickness', 'brain_lh_S_parieto_occipital_meancurv', 'brain_lh_S_cingulMarginalis_meancurv', 'brain_superiortemporal_area', 'brain_rh_Pole_occipital_thickness', 'brain_rh_S_pericallosal_meancurv', 'brain_lh_parahippocampal_volume', 'brain_rh_superiorparietal_volume', 'brain_insula_area', 'brain_rh_Lat_FisantVertical_thickness', 'brain_rh_G_postcentral_thickness', 'brain_posteriorcingulate_meancurv', 'brain_lh_S_orbitalH_Shaped_volume', 'brain_lh_GS_cingulMidAnt_thickness', 'brain_rh_S_collat_transv_post_meancurv', 'brain_lh_G_front_infOpercular_thickness', 'brain_rh_G_cingulPostdorsal_thickness', 'brain_rh_Pole_temporal_thickness', 'brain_lh_G_occipital_middle_volume', 'brain_entorhinal_area', 'brain_rh_caudalanteriorcingulate_meancurv', 'brain_rh_precuneus_meancurv', 'brain_rh_G_Ins_lgS_cent_ins_volume', 'brain_lh_lateralorbitofrontal_meancurv', 'brain_parsopercularis_thickness', 'brain_lh_GS_paracentral_area', 'brain_lh_G_front_infOrbital_meancurv', 'brain_lh_S_interm_primJensen_meancurv', 'brain_lh_S_front_middle_thickness', 'brain_lh_isthmuscingulate_thickness', 'brain_rh_GS_transv_frontopol_meancurv', 'brain_lh_parsorbitalis_volume', 'brain_rh_S_suborbital_thickness', 'brain_rh_Lat_FisantHorizont_thickness', 'brain_lh_S_temporal_inf_meancurv', 'brain_lh_paracentral_thickness', 'brain_rh_Lat_Fispost_area', 'brain_RightHippocampus', 'brain_rh_WhiteSurfArea_area', 'brain_rh_rostralanteriorcingulate_meancurv', 'brain_lh_S_octemp_lat_thickness', 'brain_rh_S_front_inf_volume', 'brain_rh_GS_cingulMidPost_meancurv', 'brain_rh_Lat_FisantHorizont_meancurv', 'brain_lh_S_occipital_ant_thickness', 'brain_lh_G_front_sup_meancurv', 'brain_lh_S_oc_middleLunatus_volume', 'brain_rh_S_circular_insula_ant_area', 'brain_lh_S_calcarine_meancurv', 'brain_OpticChiasm', 'brain_caudalmiddlefrontal_volume', 'brain_rh_S_parieto_occipital_volume', 'brain_rh_G_octemp_medParahip_meancurv', 'brain_lh_GS_cingulAnt_meancurv', 'brain_lh_GS_transv_frontopol_meancurv', 'brain_rh_G_rectus_volume', 'brain_rh_G_parietal_sup_volume', 'brain_rh_S_orbitalH_Shaped_volume', 'brain_rh_GS_frontomargin_area', 'brain_rh_S_orbital_lateral_area', 'brain_RightCerebellumCortex', 'brain_BrainSegVoltoeTIV', 'brain_lh_cuneus_area', 'brain_rh_cuneus_volume', 'brain_rh_S_subparietal_area', 'brain_rh_temporalpole_volume', 'brain_lh_G_rectus_volume', 'brain_lh_rostralanteriorcingulate_volume', 'brain_lh_temporalpole_meancurv', 'brain_lh_S_temporal_inf_volume', 'brain_rh_S_circular_insula_inf_area', 'brain_rh_S_orbital_medolfact_volume', 'brain_lh_S_temporal_sup_thickness', 'brain_lh_S_circular_insula_ant_thickness', 'brain_rh_S_temporal_sup_meancurv', 'brain_lh_S_interm_primJensen_area', 'brain_lh_G_occipital_sup_area', 'brain_lh_G_octemp_latfusifor_thickness', 'brain_rh_GS_paracentral_area', 'brain_isthmuscingulate_thickness', 'brain_Leftvessel', 'brain_rh_G_rectus_area', 'brain_rh_S_circular_insula_ant_thickness', 'brain_rh_G_subcallosal_thickness', 'brain_LeftCerebellumCortex', 'brain_lh_G_octemp_latfusifor_area', 'brain_lh_S_temporal_transverse_area', 'brain_rh_S_orbital_lateral_volume', 'brain_rh_cuneus_meancurv', 'brain_rh_rostralmiddlefrontal_volume', 'brain_lh_G_octemp_medParahip_volume', 'brain_fusiform_meancurv', 'brain_rh_S_orbitalH_Shaped_meancurv', 'brain_CerebellumCortex', 'brain_rh_S_occipital_ant_meancurv', 'brain_lh_parahippocampal_thickness', 'brain_lh_S_octemp_medLingual_thickness', 'brain_transversetemporal_meancurv', 'brain_rh_S_collat_transv_post_thickness', 'brain_lh_caudalanteriorcingulate_volume', 'brain_paracentral_volume', 'brain_rh_temporalpole_area', 'brain_rh_isthmuscingulate_thickness', 'brain_lh_S_circular_insula_inf_area', 'brain_lh_bankssts_thickness', 'brain_rh_GS_cingulAnt_volume', 'brain_@4thVentricle', 'brain_lh_S_subparietal_meancurv', 'brain_lh_fusiform_area', 'brain_rh_G_pariet_infSupramar_area', 'brain_lh_caudalanteriorcingulate_thickness', 'brain_rh_G_subcallosal_volume', 'brain_rh_GS_cingulMidPost_area', 'brain_lh_posteriorcingulate_meancurv', 'brain_paracentral_thickness', 'brain_lh_S_circular_insula_ant_volume', 'brain_rh_G_temp_supG_T_transv_meancurv', 'brain_lh_S_occipital_ant_volume', 'brain_rh_posteriorcingulate_volume', 'brain_rh_S_subparietal_meancurv', 'brain_rh_bankssts_thickness', 'brain_lh_lateralorbitofrontal_thickness', 'brain_lh_transversetemporal_area', 'brain_rh_S_orbitalH_Shaped_thickness', 'brain_lh_G_subcallosal_meancurv', 'brain_lh_G_rectus_thickness', 'brain_rh_inferiorparietal_meancurv', 'brain_precentral_thickness', 'brain_lh_parahippocampal_meancurv', 'brain_rh_S_collat_transv_ant_volume', 'brain_rh_S_subparietal_thickness', 'brain_lh_S_orbitalH_Shaped_thickness', 'brain_lh_G_orbital_thickness', 'brain_lh_S_temporal_transverse_thickness', 'brain_rh_G_parietal_sup_meancurv', 'brain_isthmuscingulate_meancurv', 'brain_lh_parstriangularis_meancurv', 'brain_rh_G_temp_supPlan_polar_volume', 'brain_lh_parsorbitalis_thickness', 'brain_rh_G_insular_short_meancurv', 'brain_RightCaudate', 'brain_rh_GS_cingulAnt_thickness', 'brain_rh_S_front_middle_thickness', 'brain_rh_parsopercularis_thickness', 'brain_lh_G_postcentral_thickness', 'brain_rh_G_occipital_sup_thickness', 'brain_CerebellumWhiteMatter', 'brain_lh_S_postcentral_volume', 'brain_lh_lateraloccipital_volume', 'brain_rh_S_octemp_medLingual_volume', 'brain_rh_pericalcarine_volume', 'brain_lh_G_occipital_middle_area', 'brain_rh_S_front_middle_volume', 'brain_lh_G_temp_supPlan_tempo_thickness', 'brain_rh_S_circular_insula_ant_meancurv', 'brain_rh_GS_cingulMidPost_thickness', 'clinical_PreCI_dichotomous_T0', 'clinical_cc_score_pre', 'clinical_LDL_HDL_ratio', 'clinical_BDZ_preop_longterm', 'clinical_past_surgery', 'clinical_EQ5D_Index_baseline', 'clinical_falling', 'clinical_TUG', 'clinical_ADL_impaired', 'clinical_GDS_imputed_preop', 'clinical_MMSE', 'clinical_premedi_benzo_yes_no_v2', 'clinical_arterial_hypertens', 'clinical_anaesthesia_duration', 'clinical_op0270_cat_v2', 'clinical_ASA_bin', 'clinical_tumorLymphomalLeukemia', 'clinical_AnticholMed_preop', 'clinical_diabetes_any', 'clinical_MNA_mal', 'clinical_MNA_risk', 'clinical_anaesth_type_combined', 'clinical_anaesth_type_general', 'height', 'age', 'weight', 'blood_T1_Proinsulinintakt', 'blood_T1_Nitrotyrosin', 'blood_T1_Calprotectinn', 'blood_T1_Zonulin_N1200', 'blood_T1_hArginin', 'blood_T1_SDMA', 'blood_T1_KNYAcid', 'blood_T1_NTproBNP_MissingRepl', 'blood_T1_CRP_InclExtrapol', 'blood_T1_S100A12', 'blood_T1_Troponin_MissingRepl', 'blood_T1_MDA_MissingRepl', 'blood_T1_KNY', 'blood_T1_TRP', 'blood_T1_Albumin_gL', 'blood_T1_ALAT_GPT_U_L', 'blood_T1_ASAT_GOT_U_L', 'blood_T1_Basophile_Percent', 'blood_T1_Creatinine_mg_dl', 'blood_T1_Creatinine_micromolL', 'blood_T1_Eosinophileabsolut', 'blood_T1_Eosinophile_Percent', 'blood_T1_Erythrozyten', 'blood_T1_gammaGTSe', 'blood_T1_Glucose_mg_dl', 'blood_T1_Glucose_mmolL', 'blood_T1_FinalGlucose_mmolL', 'blood_T1_HbA1c_Percentage', 'blood_T1_HbA1c_mmolmol', 'blood_T1_HDL_mg_dl', 'blood_T1_HDL_mmolL', 'blood_T1_HDL_mmolL_Reanalysis', 'blood_T1_FinalHDL_mmolL', 'blood_T1_Haematocrit_l_per_l', 'blood_T1_Hemoglobin', 'blood_T1_LDHSe', 'blood_T1_LDL_mg_dl', 'blood_T1_Leukocytes', 'blood_T1_Lymphozytenabsolut', 'blood_T1_Lymphozyten_Percent', 'blood_T1_MCH', 'blood_T1_MCH_fmol', 'blood_T1_MCHC', 'blood_T1_MCHC_mmolL', 'blood_T1_MCV', 'blood_T1_Monozytenabsolut', 'blood_T1_Monozyten_Percent', 'blood_T1_MPV', 'blood_T1_Neutrophileabsolut', 'blood_T1_Neutrophile_Percent', 'blood_T1_nonHDL_mg_dl', 'blood_T1_Potassium_mmolL', 'blood_T1_Reticulated_Platelets_Percent', 'blood_T1_Thrombozyten', 'blood_T1_TotalCholest_mg_dl', 'blood_T1_TotalCholesterol_mmolL', 'blood_T1_Triglyc_mg_dl', 'blood_T1_Triglycerides_mmolL', 'blood_T1_Triglyc_mmolL_Reanalysis', 'blood_T1_FinalTG_mmolL', 'blood_T1_UnreifeGranulozytenabsolut', 'blood_T1_UricAcid_mg_dl', 'blood_T1_AdipoQTotal', 'blood_T1_AdipoQHMW', 'blood_T1_NonHmwAdipon', 'blood_T1_IL6', 'blood_T1_Cpeptide_total', 'blood_T1_LeptinRec_total', 'blood_T1_Leptin_SLR_Ratio', 'blood_T1_Leptin_Adipon_Ratio', 'blood_T1_SORL1', 'blood_T1_IL2_pgml', 'blood_T1_IL8_pgml', 'blood_T1_Volk_IL8_pgml', 'blood_T1_IL18_pgml_Boraschi', 'blood_Final_T1_TP42_40']\n"
    }
   ],
   "source": [
    "selected_cols = [X_dev.columns[i] for i, indicator in enumerate(rfecv.support_) if indicator == True]\n",
    "print(selected_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean accuracy over 5 folds is 0.8313515825491873\nMean AUC over 5 folds is 0.7452537419348564\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.1, max_delta_step=0, max_depth=10,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=1000, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "run_train(X_dev.loc[:, selected_cols], Y_dev, folds_indcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_w_rank = zip(df.columns, rfecv.ranking_)\n",
    "sorted_cols_w_rank = sorted(cols_w_rank, key=lambda tup: tup[1])\n",
    "sorted_cols = [col[0] for col in sorted_cols_w_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"282.278594pt\" version=\"1.1\" viewBox=\"0 0 392.14375 282.278594\" width=\"392.14375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-09-23T12:02:44.164119</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 282.278594 \nL 392.14375 282.278594 \nL 392.14375 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 244.722344 \nL 384.94375 244.722344 \nL 384.94375 27.282344 \nL 50.14375 27.282344 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m8fc2674996\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"93.031353\" xlink:href=\"#m8fc2674996\" y=\"244.722344\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2 -->\n      <g transform=\"translate(89.850103 259.320781)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.370196\" xlink:href=\"#m8fc2674996\" y=\"244.722344\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 4 -->\n      <g transform=\"translate(145.188946 259.320781)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"203.709039\" xlink:href=\"#m8fc2674996\" y=\"244.722344\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 6 -->\n      <g transform=\"translate(200.527789 259.320781)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"259.047882\" xlink:href=\"#m8fc2674996\" y=\"244.722344\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 8 -->\n      <g transform=\"translate(255.866632 259.320781)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"314.386725\" xlink:href=\"#m8fc2674996\" y=\"244.722344\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10 -->\n      <g transform=\"translate(308.024225 259.320781)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"369.725568\" xlink:href=\"#m8fc2674996\" y=\"244.722344\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 12 -->\n      <g transform=\"translate(363.363068 259.320781)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Number of features selected -->\n     <g transform=\"translate(146.110156 272.998906)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 23.09375 72.90625 \nL 55.421875 11.921875 \nL 55.421875 72.90625 \nL 64.984375 72.90625 \nL 64.984375 0 \nL 51.703125 0 \nL 19.390625 60.984375 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-78\"/>\n       <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n       <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n       <path d=\"M 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\nM 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nz\n\" id=\"DejaVuSans-98\"/>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path id=\"DejaVuSans-32\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 37.109375 75.984375 \nL 37.109375 68.5 \nL 28.515625 68.5 \nQ 23.6875 68.5 21.796875 66.546875 \nQ 19.921875 64.59375 19.921875 59.515625 \nL 19.921875 54.6875 \nL 34.71875 54.6875 \nL 34.71875 47.703125 \nL 19.921875 47.703125 \nL 19.921875 0 \nL 10.890625 0 \nL 10.890625 47.703125 \nL 2.296875 47.703125 \nL 2.296875 54.6875 \nL 10.890625 54.6875 \nL 10.890625 58.5 \nQ 10.890625 67.625 15.140625 71.796875 \nQ 19.390625 75.984375 28.609375 75.984375 \nz\n\" id=\"DejaVuSans-102\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-78\"/>\n      <use x=\"74.804688\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"138.183594\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"235.595703\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"299.072266\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"360.595703\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"401.708984\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"433.496094\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"494.677734\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"529.882812\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"561.669922\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"596.875\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"658.398438\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"719.677734\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"758.886719\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"822.265625\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"861.128906\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"922.652344\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"974.751953\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1006.539062\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"1058.638672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1120.162109\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"1147.945312\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1209.46875\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"1264.449219\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1303.658203\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1365.181641\" xlink:href=\"#DejaVuSans-100\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m9f6fcc8401\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9f6fcc8401\" y=\"225.424495\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.55 -->\n      <g transform=\"translate(20.878125 229.223714)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9f6fcc8401\" y=\"183.33197\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.60 -->\n      <g transform=\"translate(20.878125 187.131189)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9f6fcc8401\" y=\"141.239445\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.65 -->\n      <g transform=\"translate(20.878125 145.038664)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9f6fcc8401\" y=\"99.14692\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.70 -->\n      <g transform=\"translate(20.878125 102.946138)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"50.14375\" xlink:href=\"#m9f6fcc8401\" y=\"57.054395\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.75 -->\n      <g transform=\"translate(20.878125 60.853613)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_13\">\n     <!-- Cross validation score (nb of correct classifications) -->\n     <g transform=\"translate(14.798438 264.804688)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 64.40625 67.28125 \nL 64.40625 56.890625 \nQ 59.421875 61.53125 53.78125 63.8125 \nQ 48.140625 66.109375 41.796875 66.109375 \nQ 29.296875 66.109375 22.65625 58.46875 \nQ 16.015625 50.828125 16.015625 36.375 \nQ 16.015625 21.96875 22.65625 14.328125 \nQ 29.296875 6.6875 41.796875 6.6875 \nQ 48.140625 6.6875 53.78125 8.984375 \nQ 59.421875 11.28125 64.40625 15.921875 \nL 64.40625 5.609375 \nQ 59.234375 2.09375 53.4375 0.328125 \nQ 47.65625 -1.421875 41.21875 -1.421875 \nQ 24.65625 -1.421875 15.125 8.703125 \nQ 5.609375 18.84375 5.609375 36.375 \nQ 5.609375 53.953125 15.125 64.078125 \nQ 24.65625 74.21875 41.21875 74.21875 \nQ 47.75 74.21875 53.53125 72.484375 \nQ 59.328125 70.75 64.40625 67.28125 \nz\n\" id=\"DejaVuSans-67\"/>\n       <path d=\"M 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 8.796875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nL 35.6875 0 \nL 23.484375 0 \nz\n\" id=\"DejaVuSans-118\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n       <path d=\"M 31 75.875 \nQ 24.46875 64.65625 21.28125 53.65625 \nQ 18.109375 42.671875 18.109375 31.390625 \nQ 18.109375 20.125 21.3125 9.0625 \nQ 24.515625 -2 31 -13.1875 \nL 23.1875 -13.1875 \nQ 15.875 -1.703125 12.234375 9.375 \nQ 8.59375 20.453125 8.59375 31.390625 \nQ 8.59375 42.28125 12.203125 53.3125 \nQ 15.828125 64.359375 23.1875 75.875 \nz\n\" id=\"DejaVuSans-40\"/>\n       <path d=\"M 8.015625 75.875 \nL 15.828125 75.875 \nQ 23.140625 64.359375 26.78125 53.3125 \nQ 30.421875 42.28125 30.421875 31.390625 \nQ 30.421875 20.453125 26.78125 9.375 \nQ 23.140625 -1.703125 15.828125 -13.1875 \nL 8.015625 -13.1875 \nQ 14.5 -2 17.703125 9.0625 \nQ 20.90625 20.125 20.90625 31.390625 \nQ 20.90625 42.671875 17.703125 53.65625 \nQ 14.5 64.65625 8.015625 75.875 \nz\n\" id=\"DejaVuSans-41\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-67\"/>\n      <use x=\"69.824219\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"108.6875\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"169.869141\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"221.96875\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"274.068359\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"305.855469\" xlink:href=\"#DejaVuSans-118\"/>\n      <use x=\"365.035156\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"426.314453\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"454.097656\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"481.880859\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"545.357422\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"606.636719\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"645.845703\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"673.628906\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"734.810547\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"798.189453\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"829.976562\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"882.076172\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"937.056641\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"998.238281\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1037.101562\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1098.625\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1130.412109\" xlink:href=\"#DejaVuSans-40\"/>\n      <use x=\"1169.425781\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1232.804688\" xlink:href=\"#DejaVuSans-98\"/>\n      <use x=\"1296.28125\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1328.068359\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1389.25\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"1424.455078\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1456.242188\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"1511.222656\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"1572.404297\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1611.767578\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1650.630859\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1712.154297\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"1767.134766\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1806.34375\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1838.130859\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"1893.111328\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"1920.894531\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1982.173828\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"2034.273438\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"2086.373047\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2114.15625\" xlink:href=\"#DejaVuSans-102\"/>\n      <use x=\"2149.361328\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2177.144531\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"2232.125\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"2293.404297\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"2332.613281\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"2360.396484\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"2421.578125\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"2484.957031\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"2537.056641\" xlink:href=\"#DejaVuSans-41\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#p8a9799ee66)\" d=\"M 65.361932 230.349673 \nL 93.031353 234.838707 \nL 120.700775 85.221529 \nL 148.370196 45.567444 \nL 176.039618 37.16598 \nL 203.709039 37.16598 \nL 231.378461 37.16598 \nL 259.047882 37.16598 \nL 286.717304 37.16598 \nL 314.386725 37.16598 \nL 342.056147 37.16598 \nL 369.725568 37.16598 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 244.722344 \nL 50.14375 27.282344 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 384.94375 244.722344 \nL 384.94375 27.282344 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 244.722344 \nL 384.94375 244.722344 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 27.282344 \nL 384.94375 27.282344 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p8a9799ee66\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"50.14375\" y=\"27.282344\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But: https://datascience.stackexchange.com/questions/31453/how-to-decide-what-threshold-to-use-for-removing-low-variance-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresh = (.999 * (1 - .999))\n",
    "sel = VarianceThreshold(threshold=thresh)\n",
    "X_dev_sel = sel.fit_transform(X_dev)\n",
    "print(f\"removed {X_dev.shape[1] - X_dev_sel.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_variances = pd.DataFrame(sel.variances_, index=X_dev.columns)\n",
    "feat_variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_variances = feat_variances.sort_values(by=0)\n",
    "dropped_feats = feat_variances[feat_variances < thresh].dropna() \n",
    "dropped_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After reduction\n",
    "run_train(pd.DataFrame(X_dev_sel), Y_dev, folds_indcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_transformer = GenericUnivariateSelect(score_func=mutual_info_classif, mode='percentile', param=50)\n",
    "univariate_transformer.fit(X_dev, Y_dev)\n",
    "X_dev_transformed = univariate_transformer.transform(X_dev)\n",
    "#X_test_transformed = univariate_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# After reduction\n",
    "run_train(pd.DataFrame(X_dev_transformed), Y_dev, folds_indcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices for cases that come with all image data\n",
    "imaging_dev_idcs = X_dev['brain_imaging_regions_nan']==0\n",
    "imaging_test_idcs = X_test['brain_imaging_regions_nan']==0\n",
    "\n",
    "# from the dev and test splits (created earlier) take only the imaging related data\n",
    "imaging_X_dev = X_dev.loc[imaging_dev_idcs, imaging_names]#, Y_dev[imaging_dev_idcs]\n",
    "imaging_X_test = X_test.loc[imaging_test_idcs, imaging_names]#, Y_test[imaging_test_idcs]\n",
    "\n",
    "# put all the remaining data into separate data frames\n",
    "non_imaging_df = pd.concat([df[clinical_names], df[blood_names], df[missing_feat_names], df[static_names]], axis=1)\n",
    "non_imaging_X_dev = non_imaging_df.loc[X_dev.index, :]\n",
    "non_imaging_X_test = non_imaging_df.loc[X_test.index, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     brain_lh_Pole_occipital_thickness  brain_Rightchoroidplexus  \\\n60                            1.539244                 -0.374416   \n427                          -0.871104                 -0.766456   \n518                          -0.455388                  0.956384   \n700                          -0.962158                  0.535269   \n66                           -0.019558                 -1.052315   \n..                                 ...                       ...   \n71                            0.167925                  0.402469   \n107                           1.235193                  0.313278   \n274                          -0.619872                  0.154014   \n864                           1.318107                  0.125185   \n103                           0.994496                  0.761331   \n\n     brain_lh_GS_cingulMidAnt_volume  brain_rh_Pole_occipital_area  \\\n60                         -0.472562                     -0.263226   \n427                        -0.593750                     -2.299541   \n518                        -0.459574                     -0.546986   \n700                         0.454726                     -0.877745   \n66                          0.088384                     -0.483672   \n..                               ...                           ...   \n71                         -1.126931                      0.169496   \n107                        -0.531280                     -0.195213   \n274                         0.906559                      2.756471   \n864                         0.437385                      0.989179   \n103                         1.272077                      0.563542   \n\n     brain_lh_paracentral_area  brain_rh_G_octemp_latfusifor_volume  \\\n60                   -1.178186                             0.566695   \n427                  -1.332582                            -0.978804   \n518                  -0.254966                             0.194289   \n700                  -0.623204                            -1.046354   \n66                   -0.930675                            -0.315574   \n..                         ...                                  ...   \n71                    1.234678                            -0.578580   \n107                  -0.427700                            -1.250486   \n274                   2.237341                             2.181981   \n864                   0.543433                             0.289469   \n103                   1.018706                            -0.406630   \n\n     brain_rh_superiortemporal_meancurv  brain_middletemporal_area  \\\n60                            -0.170267                   0.138149   \n427                           -1.049468                  -0.405845   \n518                            0.204496                  -0.734243   \n700                           -0.420786                  -0.049571   \n66                            -0.420786                  -1.265153   \n..                                  ...                        ...   \n71                             1.074247                   1.224787   \n107                           -1.554883                  -1.215220   \n274                            1.445000                   2.361017   \n864                            1.691509                   0.468910   \n103                           -1.681582                   0.875379   \n\n     brain_rh_S_suborbital_meancurv  brain_lh_S_circular_insula_sup_area  ...  \\\n60                        -0.311274                             1.936450  ...   \n427                       -0.469512                            -2.101892  ...   \n518                        0.013007                            -0.771936  ...   \n700                        0.347916                            -0.157062  ...   \n66                        -0.231185                            -0.875945  ...   \n..                              ...                                  ...  ...   \n71                         0.649892                             1.169334  ...   \n107                       -1.401831                            -0.133044  ...   \n274                       -0.625193                             1.345893  ...   \n864                       -1.040391                             1.128064  ...   \n103                       -0.816247                             1.044917  ...   \n\n     brain_rh_GS_cingulAnt_area  brain_lh_G_temp_supPlan_tempo_thickness  \\\n60                     0.562881                                 0.244887   \n427                   -1.613738                                 1.067479   \n518                   -0.513979                                 0.906515   \n700                   -1.057939                                 1.779763   \n66                     0.039023                                 0.128129   \n..                          ...                                      ...   \n71                     0.321509                                -0.426472   \n107                    0.186479                                -0.009611   \n274                    2.123801                                 0.244887   \n864                   -1.254694                                -0.730916   \n103                    0.176510                                -0.426472   \n\n     brain_rh_S_circular_insula_ant_meancurv  \\\n60                                 -0.527632   \n427                                -0.288309   \n518                                -1.979670   \n700                                 0.375083   \n66                                 -0.446794   \n..                                       ...   \n71                                 -0.609555   \n107                                -0.446794   \n274                                -0.609555   \n864                                 0.964260   \n103                                 0.234409   \n\n     brain_rh_GS_cingulMidPost_thickness  brain_rh_superiorparietal_meancurv  \\\n60                              0.369424                            0.345092   \n427                             0.111176                            0.960923   \n518                            -0.347438                           -0.909348   \n700                             0.427224                           -0.788114   \n66                             -0.528124                            0.345092   \n..                                   ...                                 ...   \n71                             -0.249492                            1.533134   \n107                             0.725804                            0.345092   \n274                             1.125070                            0.019709   \n864                             0.004466                            0.345092   \n103                            -0.966189                            1.252268   \n\n     brain_lh_S_orbitalH_Shaped_meancurv  \\\n60                              0.100407   \n427                             2.017976   \n518                            -1.036816   \n700                            -0.184836   \n66                              1.343674   \n..                                   ...   \n71                              1.055727   \n107                            -1.695574   \n274                             0.481703   \n864                             0.481703   \n103                             0.481703   \n\n     brain_lh_G_pariet_infAngular_thickness  brain_rh_paracentral_thickness  \\\n60                                 0.173826                       -1.522595   \n427                                0.463925                        0.476461   \n518                                0.047571                        0.341371   \n700                                1.683086                        0.116898   \n66                                -0.724260                       -1.755879   \n..                                      ...                             ...   \n71                                -1.384550                       -1.620378   \n107                                1.269085                        0.493369   \n274                                0.205378                        1.436243   \n864                                0.085456                       -0.385029   \n103                                0.167515                       -0.484889   \n\n     brain_rh_S_interm_primJensen_area  brain_Leftchoroidplexus  \n60                            0.736285                -1.518372  \n427                          -0.693065                -0.706165  \n518                          -1.183438                 0.744460  \n700                          -0.703889                 0.412097  \n66                            0.104935                -0.721341  \n..                                 ...                      ...  \n71                           -0.714738                 0.568473  \n107                          -1.064449                -0.037043  \n274                           1.888594                 1.270882  \n864                           0.884428                 0.413542  \n103                           0.489967                 0.914807  \n\n[438 rows x 1083 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>brain_lh_Pole_occipital_thickness</th>\n      <th>brain_Rightchoroidplexus</th>\n      <th>brain_lh_GS_cingulMidAnt_volume</th>\n      <th>brain_rh_Pole_occipital_area</th>\n      <th>brain_lh_paracentral_area</th>\n      <th>brain_rh_G_octemp_latfusifor_volume</th>\n      <th>brain_rh_superiortemporal_meancurv</th>\n      <th>brain_middletemporal_area</th>\n      <th>brain_rh_S_suborbital_meancurv</th>\n      <th>brain_lh_S_circular_insula_sup_area</th>\n      <th>...</th>\n      <th>brain_rh_GS_cingulAnt_area</th>\n      <th>brain_lh_G_temp_supPlan_tempo_thickness</th>\n      <th>brain_rh_S_circular_insula_ant_meancurv</th>\n      <th>brain_rh_GS_cingulMidPost_thickness</th>\n      <th>brain_rh_superiorparietal_meancurv</th>\n      <th>brain_lh_S_orbitalH_Shaped_meancurv</th>\n      <th>brain_lh_G_pariet_infAngular_thickness</th>\n      <th>brain_rh_paracentral_thickness</th>\n      <th>brain_rh_S_interm_primJensen_area</th>\n      <th>brain_Leftchoroidplexus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60</th>\n      <td>1.539244</td>\n      <td>-0.374416</td>\n      <td>-0.472562</td>\n      <td>-0.263226</td>\n      <td>-1.178186</td>\n      <td>0.566695</td>\n      <td>-0.170267</td>\n      <td>0.138149</td>\n      <td>-0.311274</td>\n      <td>1.936450</td>\n      <td>...</td>\n      <td>0.562881</td>\n      <td>0.244887</td>\n      <td>-0.527632</td>\n      <td>0.369424</td>\n      <td>0.345092</td>\n      <td>0.100407</td>\n      <td>0.173826</td>\n      <td>-1.522595</td>\n      <td>0.736285</td>\n      <td>-1.518372</td>\n    </tr>\n    <tr>\n      <th>427</th>\n      <td>-0.871104</td>\n      <td>-0.766456</td>\n      <td>-0.593750</td>\n      <td>-2.299541</td>\n      <td>-1.332582</td>\n      <td>-0.978804</td>\n      <td>-1.049468</td>\n      <td>-0.405845</td>\n      <td>-0.469512</td>\n      <td>-2.101892</td>\n      <td>...</td>\n      <td>-1.613738</td>\n      <td>1.067479</td>\n      <td>-0.288309</td>\n      <td>0.111176</td>\n      <td>0.960923</td>\n      <td>2.017976</td>\n      <td>0.463925</td>\n      <td>0.476461</td>\n      <td>-0.693065</td>\n      <td>-0.706165</td>\n    </tr>\n    <tr>\n      <th>518</th>\n      <td>-0.455388</td>\n      <td>0.956384</td>\n      <td>-0.459574</td>\n      <td>-0.546986</td>\n      <td>-0.254966</td>\n      <td>0.194289</td>\n      <td>0.204496</td>\n      <td>-0.734243</td>\n      <td>0.013007</td>\n      <td>-0.771936</td>\n      <td>...</td>\n      <td>-0.513979</td>\n      <td>0.906515</td>\n      <td>-1.979670</td>\n      <td>-0.347438</td>\n      <td>-0.909348</td>\n      <td>-1.036816</td>\n      <td>0.047571</td>\n      <td>0.341371</td>\n      <td>-1.183438</td>\n      <td>0.744460</td>\n    </tr>\n    <tr>\n      <th>700</th>\n      <td>-0.962158</td>\n      <td>0.535269</td>\n      <td>0.454726</td>\n      <td>-0.877745</td>\n      <td>-0.623204</td>\n      <td>-1.046354</td>\n      <td>-0.420786</td>\n      <td>-0.049571</td>\n      <td>0.347916</td>\n      <td>-0.157062</td>\n      <td>...</td>\n      <td>-1.057939</td>\n      <td>1.779763</td>\n      <td>0.375083</td>\n      <td>0.427224</td>\n      <td>-0.788114</td>\n      <td>-0.184836</td>\n      <td>1.683086</td>\n      <td>0.116898</td>\n      <td>-0.703889</td>\n      <td>0.412097</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>-0.019558</td>\n      <td>-1.052315</td>\n      <td>0.088384</td>\n      <td>-0.483672</td>\n      <td>-0.930675</td>\n      <td>-0.315574</td>\n      <td>-0.420786</td>\n      <td>-1.265153</td>\n      <td>-0.231185</td>\n      <td>-0.875945</td>\n      <td>...</td>\n      <td>0.039023</td>\n      <td>0.128129</td>\n      <td>-0.446794</td>\n      <td>-0.528124</td>\n      <td>0.345092</td>\n      <td>1.343674</td>\n      <td>-0.724260</td>\n      <td>-1.755879</td>\n      <td>0.104935</td>\n      <td>-0.721341</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>0.167925</td>\n      <td>0.402469</td>\n      <td>-1.126931</td>\n      <td>0.169496</td>\n      <td>1.234678</td>\n      <td>-0.578580</td>\n      <td>1.074247</td>\n      <td>1.224787</td>\n      <td>0.649892</td>\n      <td>1.169334</td>\n      <td>...</td>\n      <td>0.321509</td>\n      <td>-0.426472</td>\n      <td>-0.609555</td>\n      <td>-0.249492</td>\n      <td>1.533134</td>\n      <td>1.055727</td>\n      <td>-1.384550</td>\n      <td>-1.620378</td>\n      <td>-0.714738</td>\n      <td>0.568473</td>\n    </tr>\n    <tr>\n      <th>107</th>\n      <td>1.235193</td>\n      <td>0.313278</td>\n      <td>-0.531280</td>\n      <td>-0.195213</td>\n      <td>-0.427700</td>\n      <td>-1.250486</td>\n      <td>-1.554883</td>\n      <td>-1.215220</td>\n      <td>-1.401831</td>\n      <td>-0.133044</td>\n      <td>...</td>\n      <td>0.186479</td>\n      <td>-0.009611</td>\n      <td>-0.446794</td>\n      <td>0.725804</td>\n      <td>0.345092</td>\n      <td>-1.695574</td>\n      <td>1.269085</td>\n      <td>0.493369</td>\n      <td>-1.064449</td>\n      <td>-0.037043</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>-0.619872</td>\n      <td>0.154014</td>\n      <td>0.906559</td>\n      <td>2.756471</td>\n      <td>2.237341</td>\n      <td>2.181981</td>\n      <td>1.445000</td>\n      <td>2.361017</td>\n      <td>-0.625193</td>\n      <td>1.345893</td>\n      <td>...</td>\n      <td>2.123801</td>\n      <td>0.244887</td>\n      <td>-0.609555</td>\n      <td>1.125070</td>\n      <td>0.019709</td>\n      <td>0.481703</td>\n      <td>0.205378</td>\n      <td>1.436243</td>\n      <td>1.888594</td>\n      <td>1.270882</td>\n    </tr>\n    <tr>\n      <th>864</th>\n      <td>1.318107</td>\n      <td>0.125185</td>\n      <td>0.437385</td>\n      <td>0.989179</td>\n      <td>0.543433</td>\n      <td>0.289469</td>\n      <td>1.691509</td>\n      <td>0.468910</td>\n      <td>-1.040391</td>\n      <td>1.128064</td>\n      <td>...</td>\n      <td>-1.254694</td>\n      <td>-0.730916</td>\n      <td>0.964260</td>\n      <td>0.004466</td>\n      <td>0.345092</td>\n      <td>0.481703</td>\n      <td>0.085456</td>\n      <td>-0.385029</td>\n      <td>0.884428</td>\n      <td>0.413542</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>0.994496</td>\n      <td>0.761331</td>\n      <td>1.272077</td>\n      <td>0.563542</td>\n      <td>1.018706</td>\n      <td>-0.406630</td>\n      <td>-1.681582</td>\n      <td>0.875379</td>\n      <td>-0.816247</td>\n      <td>1.044917</td>\n      <td>...</td>\n      <td>0.176510</td>\n      <td>-0.426472</td>\n      <td>0.234409</td>\n      <td>-0.966189</td>\n      <td>1.252268</td>\n      <td>0.481703</td>\n      <td>0.167515</td>\n      <td>-0.484889</td>\n      <td>0.489967</td>\n      <td>0.914807</td>\n    </tr>\n  </tbody>\n</table>\n<p>438 rows × 1083 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "imaging_X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PCA embeddings for only the imaging data\n",
    "keep_variance = .99\n",
    "pca_imaging = PCA(keep_variance)\n",
    "\n",
    "pca_imaging.fit(imaging_X_dev)\n",
    "X_train_pca_embedding_img = pca_imaging.transform(imaging_X_dev)\n",
    "X_test_pca_embedding_img = pca_imaging.transform(imaging_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PCA created 333 components for the imaging data to preserve 99.0 % variance\n"
    }
   ],
   "source": [
    "print(f\"PCA created {len(pca_imaging.components_)} components for the imaging data to preserve {keep_variance * 100} % variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9900808727451571"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "pca_imaging.explained_variance_ratio_.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PCA embeddings for only the non-imaging data\n",
    "pca_non_imaging = PCA(keep_variance)\n",
    "\n",
    "pca_non_imaging.fit(non_imaging_X_dev)\n",
    "X_train_pca_embedding_non_img = pca_non_imaging.transform(non_imaging_X_dev)\n",
    "X_test_pca_embedding_non_img = pca_non_imaging.transform(non_imaging_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PCA created 130 components for the non-imaging data to preserve 99.0 % variance\n"
    }
   ],
   "source": [
    "print(f\"PCA created {len(pca_non_imaging.components_)} components for the non-imaging data to preserve {keep_variance * 100} % variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "272"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "len(df.columns) - len(imaging_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 4.27239663,  0.10634246, -0.13282044, ..., -0.11966609,\n        -0.01935941,  0.02197043],\n       [-2.82388566,  3.24734145,  2.16667069, ..., -0.10455753,\n        -0.22023244, -0.02950829],\n       [ 0.85255826, -0.04650894, -1.99427781, ..., -0.86049947,\n         0.32925562, -0.16178849],\n       ...,\n       [ 0.09530574, -2.59557913, -0.69482145, ...,  0.3835604 ,\n         0.19494273,  0.2421154 ],\n       [-2.6307747 ,  1.39353209, -2.23850899, ..., -0.01847253,\n         0.20844528, -0.21303641],\n       [ 4.78259881,  0.31120964, -0.20620783, ...,  0.06838571,\n        -0.2161269 ,  0.0224328 ]])"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "X_train_pca_embedding_non_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the imaging and non-imaging related embedded data\n",
    "# fill all cases where there was originally no imaging data with medians of the values from the newly created embedding\n",
    "X_dev_pca_embedding_concat = pd.concat([pd.DataFrame(X_train_pca_embedding_img).add_prefix('img'), pd.DataFrame(X_train_pca_embedding_non_img).add_prefix('non_img')], axis=1)\n",
    "X_dev_pca_embedding_concat = X_dev_pca_embedding_concat.fillna(X_dev_pca_embedding_concat.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          img0       img1       img2      img3      img4      img5      img6  \\\n0    -6.094537  -0.983051  -8.491791 -0.580337 -6.139542  6.945370 -0.952466   \n1    18.356806  -8.807269  -4.398985 -3.233303  4.576847  3.289941 -5.875206   \n2     9.514421   0.560154  10.121122  8.096299  5.593362 -5.108226  2.970522   \n3     9.311695 -13.771919  -4.844908 -4.082733  3.673129  3.026900  1.842109   \n4     6.881458   0.804666  -6.259146 -6.411789 -9.276757  1.905473  1.526727   \n..         ...        ...        ...       ...       ...       ...       ...   \n831   0.676384   0.019284   0.148250  0.114826 -0.093838  0.213259 -0.045291   \n832   0.676384   0.019284   0.148250  0.114826 -0.093838  0.213259 -0.045291   \n833   0.676384   0.019284   0.148250  0.114826 -0.093838  0.213259 -0.045291   \n834   0.676384   0.019284   0.148250  0.114826 -0.093838  0.213259 -0.045291   \n835   0.676384   0.019284   0.148250  0.114826 -0.093838  0.213259 -0.045291   \n\n         img7      img8      img9  ...  non_img120  non_img121  non_img122  \\\n0    0.247247  1.706507 -4.059223  ...   -0.140050    0.135980   -0.133206   \n1   -1.466069  1.862772  1.095599  ...    0.108389   -0.026742    0.246495   \n2   -1.611722  1.614120  2.850751  ...   -0.042951    0.499070   -0.272958   \n3   -5.864473 -0.014238 -0.739582  ...   -0.787855   -0.042836    0.117293   \n4   -3.819876 -5.360667 -3.477125  ...   -0.344208    0.620306    0.208512   \n..        ...       ...       ...  ...         ...         ...         ...   \n831 -0.121271  0.234558 -0.028000  ...    0.225889   -0.229518   -0.176741   \n832 -0.121271  0.234558 -0.028000  ...   -0.262446   -0.103295   -0.012676   \n833 -0.121271  0.234558 -0.028000  ...   -0.499132   -0.118342   -0.355147   \n834 -0.121271  0.234558 -0.028000  ...    0.009150   -0.203532   -0.259589   \n835 -0.121271  0.234558 -0.028000  ...    0.211880   -0.062920    0.016798   \n\n     non_img123  non_img124  non_img125  non_img126  non_img127  non_img128  \\\n0     -0.242470    0.262046   -0.149628    0.352965   -0.119666   -0.019359   \n1      0.271118   -0.166939   -0.412156   -0.087127   -0.104558   -0.220232   \n2     -0.093263    0.085428    0.235755    0.172011   -0.860499    0.329256   \n3     -0.015347    0.060572   -0.107178   -0.042635    0.019954    0.158044   \n4      0.382178   -0.161628   -0.177446   -0.235978   -0.455673    0.103362   \n..          ...         ...         ...         ...         ...         ...   \n831    0.005562    0.462782    0.418066   -0.023707   -0.454863   -0.149823   \n832    0.171458   -0.007507   -0.038576    0.215753    0.218966   -0.099749   \n833   -0.448501    0.373160    0.157331    0.396310    0.383560    0.194943   \n834    0.268215   -0.076716    0.289293    0.132745   -0.018473    0.208445   \n835   -0.160570    0.043358   -0.009777   -0.268783    0.068386   -0.216127   \n\n     non_img129  \n0      0.021970  \n1     -0.029508  \n2     -0.161788  \n3     -0.321720  \n4     -0.071463  \n..          ...  \n831    0.678804  \n832    0.294776  \n833    0.242115  \n834   -0.213036  \n835    0.022433  \n\n[836 rows x 463 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img0</th>\n      <th>img1</th>\n      <th>img2</th>\n      <th>img3</th>\n      <th>img4</th>\n      <th>img5</th>\n      <th>img6</th>\n      <th>img7</th>\n      <th>img8</th>\n      <th>img9</th>\n      <th>...</th>\n      <th>non_img120</th>\n      <th>non_img121</th>\n      <th>non_img122</th>\n      <th>non_img123</th>\n      <th>non_img124</th>\n      <th>non_img125</th>\n      <th>non_img126</th>\n      <th>non_img127</th>\n      <th>non_img128</th>\n      <th>non_img129</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-6.094537</td>\n      <td>-0.983051</td>\n      <td>-8.491791</td>\n      <td>-0.580337</td>\n      <td>-6.139542</td>\n      <td>6.945370</td>\n      <td>-0.952466</td>\n      <td>0.247247</td>\n      <td>1.706507</td>\n      <td>-4.059223</td>\n      <td>...</td>\n      <td>-0.140050</td>\n      <td>0.135980</td>\n      <td>-0.133206</td>\n      <td>-0.242470</td>\n      <td>0.262046</td>\n      <td>-0.149628</td>\n      <td>0.352965</td>\n      <td>-0.119666</td>\n      <td>-0.019359</td>\n      <td>0.021970</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>18.356806</td>\n      <td>-8.807269</td>\n      <td>-4.398985</td>\n      <td>-3.233303</td>\n      <td>4.576847</td>\n      <td>3.289941</td>\n      <td>-5.875206</td>\n      <td>-1.466069</td>\n      <td>1.862772</td>\n      <td>1.095599</td>\n      <td>...</td>\n      <td>0.108389</td>\n      <td>-0.026742</td>\n      <td>0.246495</td>\n      <td>0.271118</td>\n      <td>-0.166939</td>\n      <td>-0.412156</td>\n      <td>-0.087127</td>\n      <td>-0.104558</td>\n      <td>-0.220232</td>\n      <td>-0.029508</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9.514421</td>\n      <td>0.560154</td>\n      <td>10.121122</td>\n      <td>8.096299</td>\n      <td>5.593362</td>\n      <td>-5.108226</td>\n      <td>2.970522</td>\n      <td>-1.611722</td>\n      <td>1.614120</td>\n      <td>2.850751</td>\n      <td>...</td>\n      <td>-0.042951</td>\n      <td>0.499070</td>\n      <td>-0.272958</td>\n      <td>-0.093263</td>\n      <td>0.085428</td>\n      <td>0.235755</td>\n      <td>0.172011</td>\n      <td>-0.860499</td>\n      <td>0.329256</td>\n      <td>-0.161788</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9.311695</td>\n      <td>-13.771919</td>\n      <td>-4.844908</td>\n      <td>-4.082733</td>\n      <td>3.673129</td>\n      <td>3.026900</td>\n      <td>1.842109</td>\n      <td>-5.864473</td>\n      <td>-0.014238</td>\n      <td>-0.739582</td>\n      <td>...</td>\n      <td>-0.787855</td>\n      <td>-0.042836</td>\n      <td>0.117293</td>\n      <td>-0.015347</td>\n      <td>0.060572</td>\n      <td>-0.107178</td>\n      <td>-0.042635</td>\n      <td>0.019954</td>\n      <td>0.158044</td>\n      <td>-0.321720</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6.881458</td>\n      <td>0.804666</td>\n      <td>-6.259146</td>\n      <td>-6.411789</td>\n      <td>-9.276757</td>\n      <td>1.905473</td>\n      <td>1.526727</td>\n      <td>-3.819876</td>\n      <td>-5.360667</td>\n      <td>-3.477125</td>\n      <td>...</td>\n      <td>-0.344208</td>\n      <td>0.620306</td>\n      <td>0.208512</td>\n      <td>0.382178</td>\n      <td>-0.161628</td>\n      <td>-0.177446</td>\n      <td>-0.235978</td>\n      <td>-0.455673</td>\n      <td>0.103362</td>\n      <td>-0.071463</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>831</th>\n      <td>0.676384</td>\n      <td>0.019284</td>\n      <td>0.148250</td>\n      <td>0.114826</td>\n      <td>-0.093838</td>\n      <td>0.213259</td>\n      <td>-0.045291</td>\n      <td>-0.121271</td>\n      <td>0.234558</td>\n      <td>-0.028000</td>\n      <td>...</td>\n      <td>0.225889</td>\n      <td>-0.229518</td>\n      <td>-0.176741</td>\n      <td>0.005562</td>\n      <td>0.462782</td>\n      <td>0.418066</td>\n      <td>-0.023707</td>\n      <td>-0.454863</td>\n      <td>-0.149823</td>\n      <td>0.678804</td>\n    </tr>\n    <tr>\n      <th>832</th>\n      <td>0.676384</td>\n      <td>0.019284</td>\n      <td>0.148250</td>\n      <td>0.114826</td>\n      <td>-0.093838</td>\n      <td>0.213259</td>\n      <td>-0.045291</td>\n      <td>-0.121271</td>\n      <td>0.234558</td>\n      <td>-0.028000</td>\n      <td>...</td>\n      <td>-0.262446</td>\n      <td>-0.103295</td>\n      <td>-0.012676</td>\n      <td>0.171458</td>\n      <td>-0.007507</td>\n      <td>-0.038576</td>\n      <td>0.215753</td>\n      <td>0.218966</td>\n      <td>-0.099749</td>\n      <td>0.294776</td>\n    </tr>\n    <tr>\n      <th>833</th>\n      <td>0.676384</td>\n      <td>0.019284</td>\n      <td>0.148250</td>\n      <td>0.114826</td>\n      <td>-0.093838</td>\n      <td>0.213259</td>\n      <td>-0.045291</td>\n      <td>-0.121271</td>\n      <td>0.234558</td>\n      <td>-0.028000</td>\n      <td>...</td>\n      <td>-0.499132</td>\n      <td>-0.118342</td>\n      <td>-0.355147</td>\n      <td>-0.448501</td>\n      <td>0.373160</td>\n      <td>0.157331</td>\n      <td>0.396310</td>\n      <td>0.383560</td>\n      <td>0.194943</td>\n      <td>0.242115</td>\n    </tr>\n    <tr>\n      <th>834</th>\n      <td>0.676384</td>\n      <td>0.019284</td>\n      <td>0.148250</td>\n      <td>0.114826</td>\n      <td>-0.093838</td>\n      <td>0.213259</td>\n      <td>-0.045291</td>\n      <td>-0.121271</td>\n      <td>0.234558</td>\n      <td>-0.028000</td>\n      <td>...</td>\n      <td>0.009150</td>\n      <td>-0.203532</td>\n      <td>-0.259589</td>\n      <td>0.268215</td>\n      <td>-0.076716</td>\n      <td>0.289293</td>\n      <td>0.132745</td>\n      <td>-0.018473</td>\n      <td>0.208445</td>\n      <td>-0.213036</td>\n    </tr>\n    <tr>\n      <th>835</th>\n      <td>0.676384</td>\n      <td>0.019284</td>\n      <td>0.148250</td>\n      <td>0.114826</td>\n      <td>-0.093838</td>\n      <td>0.213259</td>\n      <td>-0.045291</td>\n      <td>-0.121271</td>\n      <td>0.234558</td>\n      <td>-0.028000</td>\n      <td>...</td>\n      <td>0.211880</td>\n      <td>-0.062920</td>\n      <td>0.016798</td>\n      <td>-0.160570</td>\n      <td>0.043358</td>\n      <td>-0.009777</td>\n      <td>-0.268783</td>\n      <td>0.068386</td>\n      <td>-0.216127</td>\n      <td>0.022433</td>\n    </tr>\n  </tbody>\n</table>\n<p>836 rows × 463 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "X_dev_pca_embedding_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Mean accuracy over 5 folds is 0.8026375819788992\nMean AUC over 5 folds is 0.6653132283433916\n"
    }
   ],
   "source": [
    "# Train on combined embeddings and new nan-fillings\n",
    "model = run_train(pd.DataFrame(X_dev_pca_embedding_concat), Y_dev, folds_indcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca_embedding_concat = pd.concat([pd.DataFrame(X_test_pca_embedding_img).add_prefix('img'), pd.DataFrame(X_test_pca_embedding_non_img).add_prefix('non_img')], axis=1)\n",
    "X_test_pca_embedding_concat = X_test_pca_embedding_concat.fillna(X_test_pca_embedding_concat.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "accuracy 0.7741935483870968\nauc 0.5611111111111111\n"
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test_pca_embedding_concat)\n",
    "print(\"accuracy\", accuracy_score(Y_pred, Y_test))\n",
    "print(\"auc\", roc_auc_score(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "93"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[imaging_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=(X.shape[1],))\n",
    "encoded = Dense(3, activation='relu')(input_layer)\n",
    "decoded = Dense(X.shape[1], activation='softmax')(encoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=101)\n",
    "\n",
    "autoencoder.fit(X_train, Y_train,\n",
    "                epochs=100,\n",
    "                batch_size=300,\n",
    "                shuffle=True,\n",
    "                verbose = 30,\n",
    "                validation_data=(X_test, Y_test))\n",
    "\n",
    "encoder = Model(input_layer, encoded)\n",
    "X_ae = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ae.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# 1. Define an objective function to be maximized.\n",
    "def objective(trial):\n",
    "    # 2. Suggest values of the hyperparameters using a trial object.\n",
    "    encoding_dim = trial.suggest_categorical('encoding_dim', np.arange(3, 300))\n",
    "    input_layer = Input(shape=(X.shape[1],))\n",
    "    encoded = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    decoded = Dense(X.shape[1], activation='softmax')(encoded)\n",
    "    autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "    encoder = Model(input_layer, encoded)\n",
    "    encoded_input = Input(shape=(encoding_dim,))\n",
    "    decoder = Model(encoded_input, autoencoder.layers[-1](encoded_input))\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    X_train, X_test = train_test_split(X, test_size=0.3, random_state=101)\n",
    "\n",
    "    autoencoder.fit(X_train, X_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=300,\n",
    "                    shuffle=True,\n",
    "                    verbose = False,\n",
    "                    validation_data=(X_test, X_test))\n",
    "\n",
    "    # Compute the reconstruction loss\n",
    "    \n",
    "    encoder_embeddings = encoder.predict(X_test)\n",
    "    X_pred = decoder.predict(encoder_embeddings)\n",
    "    print(X_pred.shape, X_test.shape)\n",
    "\n",
    "    mean_rec_loss = np.mean([log_loss(X_test[:, i], X_pred[:, i]) for i in range(X_test.shape[1])])\n",
    "    return mean_rec_loss\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}